{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded StandardScaler and categorical artifacts.\n",
      "Engineered features - observed min: [-1.87890062 -1.67309039 -1.79624861 -1.3500817 ] max: [1.49563575 1.70671805 1.41547433 1.37969415]\n",
      "Created cyclic encodings for time features\n",
      "Amount Distribution Analysis:\n",
      "  Mean: 1.5695, Std: 1.2634\n",
      "  Skewness: -1.0827, Kurtosis: -0.3416\n",
      "  Detected 4 peaks at: [-0.82075792 -0.50234715  1.7214741   2.53519052]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Categorical vocabulary sizes: {'merchant': 693, 'category': 14, 'gender': 2, 'street': 999, 'city': 906, 'state': 51, 'zip': 985, 'job': 497}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Owner\\anaconda3\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training with NaN prevention…\n",
      "Epoch [1/300], Loss: 21.3746\n",
      "Epoch [10/300], Loss: 16.7438\n",
      "Epoch [20/300], Loss: 14.9066\n",
      "Epoch [30/300], Loss: 14.9257\n",
      "Epoch [40/300], Loss: 13.9070\n",
      "Epoch [50/300], Loss: 12.3664\n",
      "Epoch [60/300], Loss: 12.0059\n",
      "Epoch [70/300], Loss: 10.6946\n",
      "Epoch [80/300], Loss: 10.8263\n",
      "Epoch [90/300], Loss: 9.0990\n",
      "Epoch [100/300], Loss: 8.9390\n",
      "Epoch [110/300], Loss: 7.9485\n",
      "Epoch [120/300], Loss: 8.3708\n",
      "Epoch [130/300], Loss: 8.4679\n",
      "Epoch [140/300], Loss: 7.3935\n",
      "Epoch [150/300], Loss: 7.3708\n",
      "Epoch [160/300], Loss: 7.1819\n",
      "Epoch [170/300], Loss: 7.4057\n",
      "Epoch [180/300], Loss: 7.0856\n",
      "Epoch [190/300], Loss: 6.5460\n",
      "Epoch [200/300], Loss: 5.5114\n",
      "Epoch [210/300], Loss: 5.5288\n",
      "Epoch [220/300], Loss: 5.4932\n",
      "Epoch [230/300], Loss: 4.9669\n",
      "Epoch [240/300], Loss: 4.9806\n",
      "Epoch [250/300], Loss: 5.2296\n",
      "Epoch [260/300], Loss: 4.8030\n",
      "Epoch [270/300], Loss: 4.7495\n",
      "Epoch [280/300], Loss: 4.5691\n",
      "Epoch [290/300], Loss: 4.3672\n",
      "Epoch [300/300], Loss: 4.2038\n",
      "Training complete. Saving model as 'baseline_improved_v7.pth' …\n",
      "Model saved.\n",
      "Generating synthetic samples...\n",
      "Found 4 peaks in amount distribution at: [-0.82075799 -0.50234721  1.72147407  2.53519049]\n",
      "Synthetic numeric samples shape (normalized): torch.Size([5000, 11])\n",
      "Synthetic categorical samples shape: torch.Size([5000, 8])\n",
      "Real Fraud Numeric Statistics (Original Scale):\n",
      "               amt          lat         long     city_pop    merch_lat  \\\n",
      "count  6273.000000  6273.000000  6273.000000  6273.000000  6273.000000   \n",
      "mean      5.553833    38.720264   -90.184822     8.427249    38.711246   \n",
      "std       1.627878     5.105657    14.214255     2.443052     5.140968   \n",
      "min       0.722706    20.027100  -165.672302     3.178054    19.161783   \n",
      "25%       5.479722    34.990601   -96.790901     6.679599    35.018204   \n",
      "50%       5.958528    39.455799   -87.366699     7.940228    39.451233   \n",
      "75%       6.802939    42.176701   -80.057297     9.893640    42.062038   \n",
      "max       7.227692    66.693298   -67.950302    14.882529    67.188110   \n",
      "\n",
      "        merch_long          age    trans_hour    trans_day  trans_month  \\\n",
      "count  6273.000000  6273.000000  6.273000e+03  6273.000000  6273.000000   \n",
      "mean    -90.185539    53.660290  1.396126e+01    15.704448     6.399490   \n",
      "std      14.234361    18.744579  9.707241e+00     8.773403     3.471665   \n",
      "min    -166.550781    20.000000  3.545246e-08     1.000001     1.000000   \n",
      "25%     -96.842262    38.000000  2.000000e+00     8.000000     3.000000   \n",
      "50%     -87.415649    53.000000  2.200000e+01    15.000000     6.000000   \n",
      "75%     -79.961166    66.000000  2.300000e+01    23.000000     9.000000   \n",
      "max     -66.960747   100.000000  2.300000e+01    31.000000    12.000000   \n",
      "\n",
      "       trans_dayofweek  \n",
      "count     6.273000e+03  \n",
      "mean      3.124024e+00  \n",
      "std       2.061738e+00  \n",
      "min       6.516117e-08  \n",
      "25%       9.999999e-01  \n",
      "50%       3.000000e+00  \n",
      "75%       5.000000e+00  \n",
      "max       6.000000e+00  \n",
      "\n",
      "Synthetic Fraud Numeric Statistics (After Inverse Transform):\n",
      "               amt          lat         long     city_pop    merch_lat  \\\n",
      "count  5000.000000  5000.000000  5000.000000  5000.000000  5000.000000   \n",
      "mean      5.553963    39.179211   -91.749657     8.231430    39.164837   \n",
      "std       1.627775     4.687238    13.136877     1.830882     4.673425   \n",
      "min       0.737121    22.536762  -190.573456     2.684662    23.170317   \n",
      "25%       5.480070    35.787385  -100.895000     6.979381    35.769437   \n",
      "50%       5.956661    39.528078   -90.289894     8.149983    39.519005   \n",
      "75%       6.802962    42.706405   -80.816408     9.423851    42.634427   \n",
      "max       7.227692    67.419533   -68.288353    15.099093    68.692032   \n",
      "\n",
      "        merch_long          age    trans_hour    trans_day  trans_month  \\\n",
      "count  5000.000000  5000.000000  5.000000e+03  5000.000000  5000.000000   \n",
      "mean    -91.654655    54.636501  1.424092e+01    15.728683     6.323256   \n",
      "std      13.180680    14.613059  9.276237e+00     8.153718     3.003547   \n",
      "min    -192.475204    -4.091866  3.545246e-08     1.000001     1.000000   \n",
      "25%    -100.757740    44.491199  2.875872e+00     8.537115     3.595810   \n",
      "50%     -90.180893    54.489365  1.984279e+01    15.763703     6.179188   \n",
      "75%     -80.742300    64.402975  2.252648e+01    22.857761     8.930614   \n",
      "max     -65.369072   109.738152  2.300000e+01    30.716070    12.000000   \n",
      "\n",
      "       trans_dayofweek  \n",
      "count     5.000000e+03  \n",
      "mean      3.109815e+00  \n",
      "std       2.003356e+00  \n",
      "min       6.516117e-08  \n",
      "25%       9.724438e-01  \n",
      "50%       3.030043e+00  \n",
      "75%       5.011865e+00  \n",
      "max       6.000000e+00  \n",
      "Synthetic data saved to CSV\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Improved FraudDiffuse Model – Version 7 with Amount Distribution Post-Processing\n",
    "Building on v6 with targeted improvements:\n",
    "  • Post-processing step to enforce amount distribution matching\n",
    "  • Enhanced initialization for the amount feature\n",
    "  • More aggressive weighting toward higher fraud amounts\n",
    "  • Distribution transformation matching\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import wasserstein_distance, energy_distance\n",
    "from scipy.interpolate import interp1d\n",
    "from scipy.signal import find_peaks\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "#############################################\n",
    "# Step 1: Load Preprocessed Data & Artifacts\n",
    "#############################################\n",
    "# Use raw strings to avoid escape-sequence issues.\n",
    "X_train_df = pd.read_csv(\"Data/processed/X_train.csv\")\n",
    "y_train_df = pd.read_csv(\"Data/processed/y_train.csv\")\n",
    "\n",
    "scaler = joblib.load(\"Data/processed/standard_scaler.pkl\")\n",
    "cat_vocab = joblib.load(\"Data/processed/cat_vocab.pkl\")\n",
    "cat_mapping = joblib.load(\"Data/processed/cat_mapping.pkl\")\n",
    "print(\"Loaded StandardScaler and categorical artifacts.\")\n",
    "\n",
    "# Define feature lists exactly as used during preprocessing.\n",
    "# All numeric features were standard-scaled.\n",
    "numeric_features = ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long',\n",
    "                    'age', 'trans_hour', 'trans_day', 'trans_month', 'trans_dayofweek']\n",
    "# Categorical features (factorized)\n",
    "cat_features = ['merchant', 'category', 'gender', 'street', 'city', 'state', 'zip', 'job']\n",
    "\n",
    "# Get target values (assume first column in y_train_df is target).\n",
    "y_train = y_train_df.iloc[:, 0]\n",
    "\n",
    "# Create masks.\n",
    "fraud_mask = (y_train == 1)\n",
    "nonfraud_mask = (y_train == 0)\n",
    "\n",
    "# Filter training data.\n",
    "X_train_num = X_train_df[numeric_features].loc[fraud_mask].values   # Standard-scaled numeric features.\n",
    "X_train_cat = X_train_df[cat_features].loc[fraud_mask].values         # Integer codes.\n",
    "\n",
    "X_nonfraud_num = X_train_df[numeric_features].loc[nonfraud_mask].values\n",
    "\n",
    "#############################################\n",
    "# Step 1b: Compute observed range for engineered features\n",
    "#############################################\n",
    "# Engineered features are those extracted from datetime:\n",
    "eng_features = ['trans_hour', 'trans_day', 'trans_month', 'trans_dayofweek']\n",
    "# Find their indices in \"numeric_features\"\n",
    "eng_indices = [numeric_features.index(feat) for feat in eng_features]\n",
    "\n",
    "# Also get the index for amt\n",
    "amt_idx = numeric_features.index('amt')\n",
    "\n",
    "# Compute column-wise min and max for engineered features from the fraud training set\n",
    "# (They are in standardized space.)\n",
    "eng_min_np = np.min(X_train_num[:, eng_indices], axis=0)\n",
    "eng_max_np = np.max(X_train_num[:, eng_indices], axis=0)\n",
    "# Convert to torch tensors\n",
    "eng_min = torch.tensor(eng_min_np, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "eng_max = torch.tensor(eng_max_np, dtype=torch.float32).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Engineered features - observed min:\", eng_min_np, \"max:\", eng_max_np)\n",
    "\n",
    "# Create cyclic encodings for time features\n",
    "def create_cyclic_features(data, feature_indices, periods):\n",
    "    \"\"\"Create sine and cosine features for cyclical data\"\"\"\n",
    "    cyclic_data = np.zeros((data.shape[0], len(feature_indices) * 2))\n",
    "    \n",
    "    for i, (idx, period) in enumerate(zip(feature_indices, periods)):\n",
    "        # Normalize to [0, 2π]\n",
    "        values = data[:, idx].copy()\n",
    "        normalized = 2 * np.pi * values / period\n",
    "        \n",
    "        # Create sin and cos features\n",
    "        cyclic_data[:, i*2] = np.sin(normalized)\n",
    "        cyclic_data[:, i*2+1] = np.cos(normalized)\n",
    "        \n",
    "    return cyclic_data\n",
    "\n",
    "# Define periods for each time feature (after inverse transform)\n",
    "# Note: We estimate the periods based on the feature names\n",
    "hour_period = 24.0  # 24 hours in a day\n",
    "day_period = 31.0   # Max days in a month\n",
    "month_period = 12.0 # 12 months in a year\n",
    "dow_period = 7.0    # 7 days in a week\n",
    "\n",
    "periods = [hour_period, day_period, month_period, dow_period]\n",
    "\n",
    "# Inverse transform the data to get the original scale\n",
    "X_train_num_original = scaler.inverse_transform(X_train_num)\n",
    "X_nonfraud_num_original = scaler.inverse_transform(X_nonfraud_num)\n",
    "\n",
    "# Create cyclic features using original scale data\n",
    "cyclic_fraud = create_cyclic_features(\n",
    "    X_train_num_original, \n",
    "    [numeric_features.index(feat) for feat in eng_features], \n",
    "    periods\n",
    ")\n",
    "\n",
    "cyclic_nonfraud = create_cyclic_features(\n",
    "    X_nonfraud_num_original,\n",
    "    [numeric_features.index(feat) for feat in eng_features],\n",
    "    periods\n",
    ")\n",
    "\n",
    "print(\"Created cyclic encodings for time features\")\n",
    "\n",
    "#############################################\n",
    "# Step 1c: Analyze Amount Distribution\n",
    "#############################################\n",
    "# Analyze amount distribution to understand its characteristics\n",
    "fraud_amts = X_train_num[:, amt_idx]\n",
    "\n",
    "# Calculate key statistics\n",
    "amt_mean = np.mean(fraud_amts)\n",
    "amt_std = np.std(fraud_amts)\n",
    "amt_skew = stats.skew(fraud_amts)\n",
    "amt_kurt = stats.kurtosis(fraud_amts)\n",
    "\n",
    "# Store real distribution for later matching\n",
    "real_fraud_amt_scaled = fraud_amts.copy()\n",
    "real_fraud_amt_original = X_train_num_original[:, amt_idx].copy()\n",
    "\n",
    "# Analyze for bimodality\n",
    "kde = stats.gaussian_kde(fraud_amts)\n",
    "x_grid = np.linspace(min(fraud_amts), max(fraud_amts), 1000)\n",
    "kde_values = kde(x_grid)\n",
    "peaks, _ = find_peaks(kde_values, height=0.05*kde_values.max())\n",
    "peak_x = x_grid[peaks]\n",
    "\n",
    "print(f\"Amount Distribution Analysis:\")\n",
    "print(f\"  Mean: {amt_mean:.4f}, Std: {amt_std:.4f}\")\n",
    "print(f\"  Skewness: {amt_skew:.4f}, Kurtosis: {amt_kurt:.4f}\")\n",
    "print(f\"  Detected {len(peak_x)} peaks at: {peak_x}\")\n",
    "\n",
    "# Compute CDF of the real amount distribution for later use in distribution matching\n",
    "def get_cdf(data):\n",
    "    \"\"\"Compute empirical CDF from data\"\"\"\n",
    "    sorted_data = np.sort(data)\n",
    "    ecdf_y = np.arange(1, len(sorted_data) + 1) / len(sorted_data)\n",
    "    return sorted_data, ecdf_y\n",
    "\n",
    "real_x_sorted, real_ecdf = get_cdf(fraud_amts)\n",
    "\n",
    "# Visualize the distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist(fraud_amts, bins=50, density=True, alpha=0.7)\n",
    "plt.plot(x_grid, kde_values, 'r-')\n",
    "for px in peak_x:\n",
    "    plt.axvline(x=px, color='g', linestyle='--')\n",
    "plt.title(\"Fraud Amount Distribution with Detected Peaks\")\n",
    "plt.xlabel(\"Amount (normalized)\")\n",
    "plt.ylabel(\"Density\")\n",
    "plt.show()\n",
    "\n",
    "# Store peak information for later use in generation\n",
    "peak_amounts = peak_x\n",
    "\n",
    "# NEW: Create histogram bins for amount distribution matching\n",
    "num_bins = 50\n",
    "hist_values, bin_edges = np.histogram(fraud_amts, bins=num_bins, density=True)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "# Store for later use\n",
    "amount_hist_bins = bin_edges\n",
    "amount_hist_values = hist_values\n",
    "\n",
    "#############################################\n",
    "# Step 2: Create a Custom Dataset for Fraud Samples\n",
    "#############################################\n",
    "class SparkovFraudDataset(Dataset):\n",
    "    def __init__(self, num_data, cat_data, cyclic_data):\n",
    "        self.num_data = torch.tensor(num_data, dtype=torch.float32)\n",
    "        self.cat_data = torch.tensor(cat_data, dtype=torch.long)\n",
    "        self.cyclic_data = torch.tensor(cyclic_data, dtype=torch.float32)\n",
    "    def __len__(self):\n",
    "        return self.num_data.shape[0]\n",
    "    def __getitem__(self, idx):\n",
    "        return self.num_data[idx], self.cat_data[idx], self.cyclic_data[idx]\n",
    "\n",
    "fraud_dataset = SparkovFraudDataset(X_train_num, X_train_cat, cyclic_fraud)\n",
    "\n",
    "#############################################\n",
    "# Step 3: Set Device and Diffusion Hyperparameters\n",
    "#############################################\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "T_train = 800\n",
    "beta_start = 1e-4\n",
    "beta_end = 0.02\n",
    "beta = torch.linspace(beta_start, beta_end, T_train).to(device)\n",
    "alpha = 1.0 - beta\n",
    "alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "\n",
    "# UPDATED: Further increase weight for amount loss\n",
    "w1 = 0.10  # Prior weight\n",
    "w2 = 0.40  # Triplet loss weight\n",
    "lambda_eng = 0.05  # Weight for engineered range loss\n",
    "lambda_amt = 0.20  # Increased from 0.15 to focus even more on amount distribution\n",
    "\n",
    "#############################################\n",
    "# Step 4: Define the Diffusion Model\n",
    "#############################################\n",
    "class CombinedNoisePredictor(nn.Module):\n",
    "    \"\"\"\n",
    "    Enhanced version that handles cyclic time encodings\n",
    "    \"\"\"\n",
    "    def __init__(self, num_input_dim, cat_vocab_sizes, cyclic_dim=8, cat_embed_dim=4, hidden_dim=256):\n",
    "        super(CombinedNoisePredictor, self).__init__()\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        for col, vocab in cat_vocab_sizes.items():\n",
    "            self.embeddings[col] = nn.Embedding(vocab, cat_embed_dim)\n",
    "        cat_total_dim = len(cat_vocab_sizes) * cat_embed_dim\n",
    "        \n",
    "        # Now includes cyclic dimensions in the input\n",
    "        combined_input_dim = num_input_dim + cat_total_dim + cyclic_dim\n",
    "        \n",
    "        # Simpler network with gentle residual connections to avoid NaN issues\n",
    "        self.fc1 = nn.Linear(combined_input_dim + 1, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc4 = nn.Linear(hidden_dim, combined_input_dim)\n",
    "        \n",
    "        # FIXED: Use LayerNorm for more robust normalization\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # FIXED: Use ReLU for more stability (SiLU can sometimes cause issues)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Initialize weights carefully to avoid exploding gradients\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "        nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        nn.init.xavier_uniform_(self.fc4.weight)\n",
    "        \n",
    "    def forward(self, x_num, x_cat, x_cyclic, t):\n",
    "        embeds = []\n",
    "        for i, col in enumerate(self.embeddings):\n",
    "            emb = self.embeddings[col](x_cat[:, i])\n",
    "            embeds.append(emb)\n",
    "        x_cat_emb = torch.cat(embeds, dim=1)\n",
    "        \n",
    "        # Include cyclic features in the concatenation\n",
    "        x = torch.cat([x_num, x_cat_emb, x_cyclic], dim=1)\n",
    "        \n",
    "        t_norm = t.unsqueeze(1).float() / T_train\n",
    "        x_input = torch.cat([x, t_norm], dim=1)\n",
    "        \n",
    "        # More stable implementation with layer normalization\n",
    "        h = self.activation(self.fc1(x_input))\n",
    "        h = self.norm1(h)\n",
    "        h = self.dropout(h)\n",
    "        \n",
    "        h_res = h\n",
    "        h = self.activation(self.fc2(h))\n",
    "        h = self.norm2(h)\n",
    "        h = self.dropout(h)\n",
    "        h = h + 0.1 * h_res  # Gentle residual connection\n",
    "        \n",
    "        h_res = h\n",
    "        h = self.activation(self.fc3(h))\n",
    "        h = self.norm3(h)\n",
    "        h = self.dropout(h)\n",
    "        h = h + 0.1 * h_res  # Gentle residual connection\n",
    "        \n",
    "        out = self.fc4(h)\n",
    "        \n",
    "        return out\n",
    "\n",
    "cat_vocab_sizes = {col: cat_vocab[col] for col in cat_features}\n",
    "print(\"Categorical vocabulary sizes:\", cat_vocab_sizes)\n",
    "\n",
    "num_input_dim = len(numeric_features)\n",
    "cyclic_dim = len(eng_features) * 2  # sin & cos for each time feature\n",
    "\n",
    "model = CombinedNoisePredictor(\n",
    "    num_input_dim=num_input_dim,\n",
    "    cat_vocab_sizes=cat_vocab_sizes,\n",
    "    cyclic_dim=cyclic_dim,\n",
    "    cat_embed_dim=4,\n",
    "    hidden_dim=256  # Reduced from 320 for stability\n",
    ").to(device)\n",
    "\n",
    "#############################################\n",
    "# Step 5: Define Loss Functions, Forward Diffusion, and Feature-Specific Losses\n",
    "#############################################\n",
    "X_nonfraud_tensor = torch.tensor(X_nonfraud_num, dtype=torch.float32).to(device)\n",
    "X_cyclic_nonfraud_tensor = torch.tensor(cyclic_nonfraud, dtype=torch.float32).to(device)\n",
    "mu_nf = X_nonfraud_tensor.mean(dim=0, keepdim=True)\n",
    "sigma_nf = X_nonfraud_tensor.std(dim=0, keepdim=True) + 1e-5\n",
    "\n",
    "def forward_diffusion(x0, t):\n",
    "    sqrt_alpha_hat_t = torch.sqrt(alpha_hat[t]).unsqueeze(1)\n",
    "    sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - alpha_hat[t]).unsqueeze(1)\n",
    "    noise = torch.randn_like(x0).to(device)\n",
    "    x_t = sqrt_alpha_hat_t * x0 + sqrt_one_minus_alpha_hat_t * noise\n",
    "    return x_t, noise\n",
    "\n",
    "def compute_feature_weighted_Lnorm(pred_noise, true_noise):\n",
    "    # Refined feature weights based on v2 results\n",
    "    feature_weights = torch.ones(num_input_dim, device=device)\n",
    "    \n",
    "    # Indices in numeric_features for challenging features\n",
    "    amt_idx = numeric_features.index('amt')\n",
    "    hour_idx = numeric_features.index('trans_hour')\n",
    "    month_idx = numeric_features.index('trans_month')\n",
    "    dow_idx = numeric_features.index('trans_dayofweek')\n",
    "    day_idx = numeric_features.index('trans_day')\n",
    "    \n",
    "    # Apply weights based on v2 performance, but gentler for stability\n",
    "    feature_weights[amt_idx] = 1.8      # Further increased weight for amount\n",
    "    feature_weights[hour_idx] = 1.3     # Adjusted for trans_hour \n",
    "    feature_weights[month_idx] = 1.1    # Slightly increased\n",
    "    feature_weights[dow_idx] = 1.1      # Slightly increased\n",
    "    feature_weights[day_idx] = 1.0      # Keeping neutral weight for trans_day\n",
    "    \n",
    "    # Weighted MSE\n",
    "    squared_diff = (pred_noise - true_noise)**2\n",
    "    weighted_squared_diff = squared_diff * feature_weights.unsqueeze(0)\n",
    "    return weighted_squared_diff.mean()\n",
    "\n",
    "# FIXED: Safer Lprior computation that prevents NaN values\n",
    "def compute_Lprior(pred_noise):\n",
    "    # Add epsilon to sigma to prevent division by very small values\n",
    "    z = (pred_noise - mu_nf) / (sigma_nf + 1e-5)\n",
    "    \n",
    "    # Clip to prevent extreme values\n",
    "    z = torch.clamp(z, -10.0, 10.0)\n",
    "    z_abs = torch.abs(z)\n",
    "    \n",
    "    # Handle CDF calculation safely with exception catching\n",
    "    try:\n",
    "        normal = torch.distributions.Normal(0, 1)\n",
    "        prob = 1 - normal.cdf(z_abs)\n",
    "        L_prior = 1 - 2 * prob\n",
    "        return L_prior.mean()\n",
    "    except Exception as e:\n",
    "        # Fallback to simpler loss if CDF fails\n",
    "        print(f\"CDF calculation failed: {e}. Using fallback loss.\")\n",
    "        return 0.1 * F.mse_loss(pred_noise, torch.zeros_like(pred_noise))\n",
    "\n",
    "def triplet_loss(anchor, positive, negative, margin=1.0):\n",
    "    pos_distance = F.pairwise_distance(anchor, positive, p=2)\n",
    "    neg_distance = F.pairwise_distance(anchor, negative, p=2)\n",
    "    loss = F.relu(pos_distance - neg_distance + margin)\n",
    "    return loss.mean()\n",
    "\n",
    "def engineered_range_loss(x0_est_eng, eng_min, eng_max):\n",
    "    # Penalize values below eng_min or above eng_max.\n",
    "    lower_penalty = F.relu(eng_min - x0_est_eng)\n",
    "    upper_penalty = F.relu(x0_est_eng - eng_max)\n",
    "    return torch.mean(lower_penalty + upper_penalty)\n",
    "\n",
    "# IMPROVED: Enhanced amount distribution loss with stronger high-value emphasis\n",
    "def amount_distribution_loss(x0_est_amt, real_amt):\n",
    "    \"\"\"Enhanced loss for better bimodal amount distribution matching\"\"\"\n",
    "    # Calculate basic statistical matches\n",
    "    batch_mean = x0_est_amt.mean()\n",
    "    real_mean = real_amt.mean()\n",
    "    mean_diff = (batch_mean - real_mean).abs()\n",
    "    \n",
    "    # Get quantiles from both distributions - focus on upper quantiles\n",
    "    # since this is where we're seeing mismatch\n",
    "    try:\n",
    "        # Safely calculate percentiles\n",
    "        x0_np = x0_est_amt.detach().cpu().numpy()\n",
    "        real_np = real_amt.detach().cpu().numpy()\n",
    "        \n",
    "        # Calculate key percentiles, especially focusing on higher ones\n",
    "        # for fraud amounts\n",
    "        x0_q50 = torch.tensor(np.percentile(x0_np, 50)).to(device)\n",
    "        real_q50 = torch.tensor(np.percentile(real_np, 50)).to(device)\n",
    "        x0_q75 = torch.tensor(np.percentile(x0_np, 75)).to(device)\n",
    "        real_q75 = torch.tensor(np.percentile(real_np, 75)).to(device)\n",
    "        x0_q90 = torch.tensor(np.percentile(x0_np, 90)).to(device)\n",
    "        real_q90 = torch.tensor(np.percentile(real_np, 90)).to(device)\n",
    "        x0_q95 = torch.tensor(np.percentile(x0_np, 95)).to(device)\n",
    "        real_q95 = torch.tensor(np.percentile(real_np, 95)).to(device)\n",
    "        \n",
    "        # Compute skewness for both distributions\n",
    "        # (The fraud amount distribution has negative skew we need to match)\n",
    "        real_centered = real_np - np.mean(real_np)\n",
    "        real_skew = np.mean((real_centered / np.std(real_centered))**3)\n",
    "        \n",
    "        x0_centered = x0_np - np.mean(x0_np)\n",
    "        x0_skew = np.mean((x0_centered / (np.std(x0_centered) + 1e-8))**3)\n",
    "        \n",
    "        skew_diff = np.abs(real_skew - x0_skew)\n",
    "        skew_tensor = torch.tensor(skew_diff).to(device)\n",
    "        \n",
    "        # IMPROVED: Higher weights on the upper percentiles and skewness\n",
    "        # to ensure we match the higher-value fraud distribution\n",
    "        return mean_diff + \\\n",
    "               1.0 * (x0_q50 - real_q50).abs() + \\\n",
    "               3.0 * (x0_q75 - real_q75).abs() + \\\n",
    "               5.0 * (x0_q90 - real_q90).abs() + \\\n",
    "               8.0 * (x0_q95 - real_q95).abs() + \\\n",
    "               4.0 * skew_tensor  # Increased skewness importance\n",
    "    except Exception as e:\n",
    "        print(f\"Error in percentile calculation: {e}, using mean difference only\")\n",
    "        return mean_diff\n",
    "\n",
    "#############################################\n",
    "# Step 6: Train the Diffusion Model (Fraud Samples Only)\n",
    "#############################################\n",
    "# IMPROVED: Slightly smaller batch size for initial stability\n",
    "loader = DataLoader(fraud_dataset, batch_size=32, shuffle=True)\n",
    "num_epochs = 300  # Reduced from 600\n",
    "# IMPROVED: Even lower learning rate for stability\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0003, weight_decay=1e-5)  # Added weight decay\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.7, patience=15, verbose=True\n",
    ")\n",
    "\n",
    "# Convert real amount data to tensor for use in amount_distribution_loss\n",
    "X_real_amt = torch.tensor(X_train_num[:, amt_idx], dtype=torch.float32).to(device)\n",
    "\n",
    "print(\"Starting training with NaN prevention…\")\n",
    "for epoch in range(num_epochs):\n",
    "    # Start increasing weights only after model is stable\n",
    "    if epoch > 200 and epoch % 50 == 0:\n",
    "        lambda_amt = min(0.25, lambda_amt * 1.05)  # Very gentle increase every 50 epochs\n",
    "\n",
    "    epoch_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for batch in loader:\n",
    "        x0_num, x0_cat, x0_cyclic = batch\n",
    "        x0_num = x0_num.to(device)\n",
    "        x0_cat = x0_cat.to(device)\n",
    "        x0_cyclic = x0_cyclic.to(device)\n",
    "        batch_size = x0_num.shape[0]\n",
    "        \n",
    "        # Skip batches that are too small (can cause std issues)\n",
    "        if batch_size <= 1:\n",
    "            continue\n",
    "            \n",
    "        # FIXED: Use a more stable t sampling to avoid extreme values\n",
    "        t = torch.randint(1, T_train-1, (batch_size,), device=device)  # Avoid t=0 and t=T_train-1\n",
    "        \n",
    "        # Forward diffusion\n",
    "        x_t_num, true_noise = forward_diffusion(x0_num, t)\n",
    "        \n",
    "        # Check for NaNs\n",
    "        if torch.isnan(x_t_num).any():\n",
    "            print(\"NaN detected in x_t_num, skipping batch\")\n",
    "            continue\n",
    "            \n",
    "        # Forward through model\n",
    "        pred_noise = model(x_t_num, x0_cat, x0_cyclic, t)\n",
    "        \n",
    "        # Check for NaNs\n",
    "        if torch.isnan(pred_noise).any():\n",
    "            print(\"NaN detected in pred_noise, skipping batch\")\n",
    "            continue\n",
    "            \n",
    "        # Extract predicted noise for numeric features\n",
    "        pred_noise_numeric = pred_noise[:, :num_input_dim]\n",
    "        \n",
    "        # Safe loss calculations with gradient clipping built-in\n",
    "        L_norm = compute_feature_weighted_Lnorm(pred_noise_numeric, true_noise)\n",
    "        \n",
    "        # Safer version of L_prior\n",
    "        try:\n",
    "            L_prior = compute_Lprior(pred_noise_numeric)\n",
    "            if torch.isnan(L_prior):\n",
    "                print(\"NaN in L_prior, using fallback\")\n",
    "                L_prior = 0.1 * torch.mean(pred_noise_numeric**2)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in L_prior: {e}, using fallback\")\n",
    "            L_prior = 0.1 * torch.mean(pred_noise_numeric**2)\n",
    "        \n",
    "        # Calculate x0_est with numerical stability measures\n",
    "        sqrt_alpha_hat_t = torch.sqrt(alpha_hat[t]).unsqueeze(1)\n",
    "        sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - alpha_hat[t]).unsqueeze(1)\n",
    "        \n",
    "        # Safer x0 estimation with clamping\n",
    "        x0_est = (x_t_num - sqrt_one_minus_alpha_hat_t * pred_noise_numeric) / (sqrt_alpha_hat_t + 1e-8)\n",
    "        x0_est = torch.clamp(x0_est, -10.0, 10.0)  # Prevent extreme values\n",
    "        \n",
    "        if torch.isnan(x0_est).any():\n",
    "            print(\"NaN detected in x0_est, skipping batch\")\n",
    "            continue\n",
    "        \n",
    "        # Get negative samples for triplet loss\n",
    "        neg_indices = torch.randint(0, X_nonfraud_tensor.shape[0], (batch_size,), device=device)\n",
    "        negative_sample = X_nonfraud_tensor[neg_indices]\n",
    "        \n",
    "        # Compute triplet loss\n",
    "        try:\n",
    "            L_triplet = triplet_loss(x0_est, x0_num, negative_sample)\n",
    "            if torch.isnan(L_triplet):\n",
    "                print(\"NaN in L_triplet, using fallback\")\n",
    "                L_triplet = torch.tensor(0.0).to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in L_triplet: {e}, using fallback\")\n",
    "            L_triplet = torch.tensor(0.0).to(device)\n",
    "        \n",
    "        # Compute engineered range loss\n",
    "        x0_est_eng = x0_est[:, eng_indices]\n",
    "        try:\n",
    "            L_eng = engineered_range_loss(x0_est_eng, eng_min, eng_max)\n",
    "            if torch.isnan(L_eng):\n",
    "                print(\"NaN in L_eng, using fallback\")\n",
    "                L_eng = torch.tensor(0.0).to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in L_eng: {e}, using fallback\")\n",
    "            L_eng = torch.tensor(0.0).to(device)\n",
    "        \n",
    "        # Compute amount-specific loss\n",
    "        x0_est_amt = x0_est[:, amt_idx]\n",
    "        try:\n",
    "            L_amt = amount_distribution_loss(x0_est_amt, X_real_amt[:batch_size])\n",
    "            if torch.isnan(L_amt):\n",
    "                print(\"NaN in L_amt, using fallback\")\n",
    "                L_amt = torch.tensor(0.0).to(device)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in L_amt: {e}, using fallback\")\n",
    "            L_amt = torch.tensor(0.0).to(device)\n",
    "        \n",
    "        # Final loss with NaN checking\n",
    "        total_loss = L_norm + w1 * L_prior + w2 * L_triplet + lambda_eng * L_eng + lambda_amt * L_amt\n",
    "        \n",
    "        if torch.isnan(total_loss):\n",
    "            print(\"NaN in total_loss, skipping batch\")\n",
    "            continue\n",
    "            \n",
    "        optimizer.zero_grad()\n",
    "        total_loss.backward()\n",
    "        \n",
    "        # IMPROVED: Aggressive gradient clipping\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "        \n",
    "        optimizer.step()\n",
    "        epoch_loss += total_loss.item()\n",
    "        num_batches += 1\n",
    "    \n",
    "    # Safe average calculation\n",
    "    avg_loss = epoch_loss / max(1, num_batches)\n",
    "    \n",
    "    # Update learning rate based on loss\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0 or epoch == 0:\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"Training complete. Saving model as 'baseline_improved_v7.pth' …\")\n",
    "torch.save(model.state_dict(), \"Data/baseline_improved_v7.pth\")\n",
    "print(\"Model saved.\")\n",
    "\n",
    "#############################################\n",
    "# NEW: Define Distribution Matching Functions for Post-Processing\n",
    "#############################################\n",
    "def get_distribution_transform_function(source_vals, target_vals):\n",
    "    \"\"\"\n",
    "    Creates a function that transforms values from source distribution to target distribution\n",
    "    through quantile matching\n",
    "    \"\"\"\n",
    "    # Get CDFs\n",
    "    source_sorted, source_cdf = get_cdf(source_vals)\n",
    "    target_sorted, target_cdf = get_cdf(target_vals)\n",
    "    \n",
    "    # Create interpolation functions\n",
    "    source_to_quantile = interp1d(source_sorted, source_cdf, \n",
    "                                 bounds_error=False, fill_value=(0, 1))\n",
    "    quantile_to_target = interp1d(target_cdf, target_sorted, \n",
    "                                 bounds_error=False, \n",
    "                                 fill_value=(min(target_sorted), max(target_sorted)))\n",
    "    \n",
    "    # Return the composition of the two functions\n",
    "    def transform(vals):\n",
    "        quantiles = source_to_quantile(vals)\n",
    "        return quantile_to_target(quantiles)\n",
    "    \n",
    "    return transform\n",
    "\n",
    "def match_distribution(values, target_values):\n",
    "    \"\"\"\n",
    "    Transform values to match the distribution of target_values\n",
    "    \"\"\"\n",
    "    transform = get_distribution_transform_function(values, target_values)\n",
    "    return transform(values)\n",
    "\n",
    "#############################################\n",
    "# Step 7: Generate Synthetic Fraud Samples with Distribution Post-Processing\n",
    "#############################################\n",
    "def generate_synthetic_fraud(model, num_samples, T_gen=600):  # Reduced T_gen\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create categorical samples\n",
    "        cat_samples = {}\n",
    "        for col in cat_vocab_sizes:\n",
    "            vocab_size = cat_vocab_sizes[col]\n",
    "            cat_samples[col] = torch.randint(0, vocab_size, (num_samples,), device=device, dtype=torch.long)\n",
    "        x_cat = torch.stack([cat_samples[col] for col in cat_features], dim=1)\n",
    "        \n",
    "        X_fraud_tensor = torch.tensor(X_train_num, dtype=torch.float32).to(device)\n",
    "        \n",
    "        # IMPROVED: Better initialization with bimodal distribution awareness\n",
    "        # Create a mixture of two distributions to better match bimodal patterns\n",
    "        idx1 = torch.randint(0, X_fraud_tensor.shape[0] // 2, (num_samples // 2,), device=device)\n",
    "        idx2 = torch.randint(X_fraud_tensor.shape[0] // 2, X_fraud_tensor.shape[0], (num_samples - num_samples // 2,), device=device)\n",
    "        idx = torch.cat([idx1, idx2])\n",
    "        \n",
    "        # Add controlled noise\n",
    "        noise = torch.randn(num_samples, num_input_dim).to(device) * 0.3  # Reduced noise\n",
    "        x_t_num = X_fraud_tensor[idx] + X_fraud_tensor.std(dim=0, keepdim=True) * noise\n",
    "        \n",
    "        # Create cyclic features for generation\n",
    "        X_cyclic_fraud_tensor = torch.tensor(cyclic_fraud, dtype=torch.float32).to(device)\n",
    "        x_cyclic = X_cyclic_fraud_tensor[idx]\n",
    "        \n",
    "        # IMPROVED: Enhanced handling for amount to better match bimodal distribution\n",
    "        amt_idx = numeric_features.index('amt')\n",
    "        \n",
    "        # Get real fraud amount distribution\n",
    "        fraud_amts = X_fraud_tensor[:, amt_idx]\n",
    "        \n",
    "        # Use KDE to find the peaks in the distribution\n",
    "        fraud_amts_np = fraud_amts.cpu().numpy()\n",
    "        kde = stats.gaussian_kde(fraud_amts_np)\n",
    "        x_grid = np.linspace(fraud_amts_np.min(), fraud_amts_np.max(), 1000)\n",
    "        kde_values = kde(x_grid)\n",
    "        \n",
    "        # Find peaks in the KDE\n",
    "        peaks, _ = find_peaks(kde_values, height=0.05*kde_values.max())\n",
    "        peak_x = x_grid[peaks]\n",
    "        print(f\"Found {len(peak_x)} peaks in amount distribution at: {peak_x}\")\n",
    "        \n",
    "        # If at least two peaks found, use them for initialization\n",
    "        if len(peak_x) >= 2:\n",
    "            # Sort peaks to ensure higher amounts are at the end\n",
    "            peak_x = sorted(peak_x)\n",
    "            \n",
    "            # IMPROVED: Even more weight on higher amounts - 90% high, 10% low\n",
    "            high_peak_samples = int(num_samples * 0.9)  # Changed from 0.8 to 0.9\n",
    "            low_peak_samples = num_samples - high_peak_samples\n",
    "            \n",
    "            # Generate samples around each peak with controlled noise\n",
    "            low_peak = torch.tensor(peak_x[0], device=device)\n",
    "            high_peak = torch.tensor(peak_x[-1], device=device)\n",
    "            \n",
    "            # Add noise scaled to distance between peaks for realistic variation\n",
    "            peak_distance = high_peak - low_peak\n",
    "            low_noise = torch.randn(low_peak_samples, device=device) * (0.10 * peak_distance)  # Reduced noise\n",
    "            high_noise = torch.randn(high_peak_samples, device=device) * (0.08 * peak_distance)  # Reduced noise\n",
    "            \n",
    "            # Create the bimodal sample\n",
    "            low_amts = low_peak + low_noise\n",
    "            high_amts = high_peak + high_noise\n",
    "            \n",
    "            # Combine and shuffle\n",
    "            amt_values = torch.cat([low_amts, high_amts])\n",
    "            perm = torch.randperm(num_samples)\n",
    "            amt_values = amt_values[perm]\n",
    "            \n",
    "            # Replace the amount values in our initialization\n",
    "            x_t_num[:, amt_idx] = amt_values\n",
    "        else:\n",
    "            # Fallback: use more traditional approach with upper/lower thirds\n",
    "            sorted_amts, _ = torch.sort(fraud_amts)\n",
    "            n = sorted_amts.size(0)\n",
    "            \n",
    "            # IMPROVED: Use even more asymmetric mixture - 90% from upper range\n",
    "            lower_idx = torch.randint(0, n // 3, (num_samples // 10,), device=device)  # Changed from 20% to 10%\n",
    "            upper_idx = torch.randint(2 * n // 3, n, (num_samples - num_samples // 10,), device=device)  # 90%\n",
    "            \n",
    "            # Combined indices\n",
    "            amt_indices = torch.cat([lower_idx, upper_idx])\n",
    "            # Add small noise to prevent exact duplicates\n",
    "            amt_noise = torch.randn(num_samples, device=device) * 0.08  # Reduced noise further\n",
    "            \n",
    "            # Replace amount values with our bimodal-aware initialization\n",
    "            x_t_num[:, amt_idx] = sorted_amts[amt_indices] + amt_noise\n",
    "        \n",
    "        # Reverse diffusion process\n",
    "        for t_step in reversed(range(1, T_gen)):\n",
    "            t = torch.full((num_samples,), t_step, device=device, dtype=torch.long)\n",
    "            \n",
    "            # Predict noise\n",
    "            pred_noise = model(x_t_num, x_cat, x_cyclic, t)\n",
    "            pred_noise_numeric = pred_noise[:, :num_input_dim]\n",
    "            \n",
    "            # Clamp predicted noise to avoid extreme values\n",
    "            pred_noise_numeric = torch.clamp(pred_noise_numeric, -5.0, 5.0)\n",
    "            \n",
    "            beta_t = beta[t].unsqueeze(1)\n",
    "            sqrt_alpha_t = torch.sqrt(alpha[t]).unsqueeze(1)\n",
    "            sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - alpha_hat[t]).unsqueeze(1)\n",
    "            \n",
    "            # IMPROVED: Adaptive noise reduction\n",
    "            noise_scale = torch.sqrt(beta_t)\n",
    "            if t_step < 200:  # Reduce noise in later steps\n",
    "                noise_scale = noise_scale * (t_step / 200.0)\n",
    "            \n",
    "            z = torch.randn_like(x_t_num) * noise_scale if t_step > 1 else torch.zeros_like(x_t_num)\n",
    "            \n",
    "                        # Update sample with stable computation (avoid division by very small numbers)\n",
    "            x_t_num = (x_t_num - (beta_t / (sqrt_one_minus_alpha_hat_t + 1e-8)) * pred_noise_numeric) / (sqrt_alpha_t + 1e-8) + z\n",
    "            \n",
    "            # Clamp to avoid extreme values\n",
    "            x_t_num = torch.clamp(x_t_num, -10.0, 10.0)\n",
    "        \n",
    "        # After reverse diffusion, clip engineered features to observed range.\n",
    "        x_t_num_clipped = x_t_num.clone()\n",
    "        x0_est_eng = x_t_num[:, eng_indices]\n",
    "        x0_est_eng = torch.max(torch.min(x0_est_eng, eng_max.unsqueeze(0)), eng_min.unsqueeze(0))\n",
    "        x_t_num_clipped[:, eng_indices] = x0_est_eng\n",
    "        \n",
    "        # NEW: Post-processing step to directly fix amount distribution\n",
    "        # Extract the synthetic amount values\n",
    "        syn_amt_values = x_t_num_clipped[:, amt_idx].cpu().numpy()\n",
    "        \n",
    "        # Apply distribution matching to transform synthetic amounts to match real distribution\n",
    "        transformed_amt = match_distribution(syn_amt_values, real_fraud_amt_scaled)\n",
    "        \n",
    "        # Replace the amount values with the transformed ones\n",
    "        x_t_num_clipped[:, amt_idx] = torch.tensor(transformed_amt, dtype=torch.float32).to(device)\n",
    "        \n",
    "        return x_t_num_clipped, x_cat\n",
    "\n",
    "# Generate synthetic samples\n",
    "num_synthetic = 5000\n",
    "print(\"Generating synthetic samples...\")\n",
    "synthetic_num_norm, synthetic_cat = generate_synthetic_fraud(model, num_synthetic)\n",
    "print(\"Synthetic numeric samples shape (normalized):\", synthetic_num_norm.shape)\n",
    "print(\"Synthetic categorical samples shape:\", synthetic_cat.shape)\n",
    "\n",
    "#############################################\n",
    "# Step 8: Inverse Transform Numeric Features to Original Scale\n",
    "#############################################\n",
    "synthetic_num_norm_np = synthetic_num_norm.cpu().numpy()\n",
    "synthetic_num_original = scaler.inverse_transform(synthetic_num_norm_np)\n",
    "\n",
    "#############################################\n",
    "# Step 9: Combine Numeric and Categorical Parts and Evaluate\n",
    "#############################################\n",
    "synthetic_numeric_df = pd.DataFrame(synthetic_num_original, columns=numeric_features)\n",
    "synthetic_cat_df = pd.DataFrame(synthetic_cat.cpu().numpy(), columns=cat_features)\n",
    "synthetic_full_df = pd.concat([synthetic_numeric_df, synthetic_cat_df], axis=1)\n",
    "\n",
    "X_fraud_tensor = torch.tensor(X_train_num, dtype=torch.float32)\n",
    "real_numeric = scaler.inverse_transform(X_fraud_tensor.cpu().numpy())\n",
    "real_numeric_df = pd.DataFrame(real_numeric, columns=numeric_features)\n",
    "\n",
    "print(\"Real Fraud Numeric Statistics (Original Scale):\")\n",
    "print(real_numeric_df.describe())\n",
    "print(\"\\nSynthetic Fraud Numeric Statistics (After Inverse Transform):\")\n",
    "print(synthetic_numeric_df.describe())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the synthetic data\n",
    "synthetic_full_df.to_csv(\"Data/synthetic_fraud_v7.csv\", index=False)\n",
    "print(\"Synthetic data saved to CSV\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, classification_report, f1_score\n",
    "import joblib\n",
    "\n",
    "# -------------------------------\n",
    "# 1. Load Validation and Test Data\n",
    "# -------------------------------\n",
    "X_val = pd.read_csv(\"Data/processed/X_val.csv\")\n",
    "y_val = pd.read_csv(\"Data/processed/y_val.csv\").iloc[:, 0]  # assuming target is the first column\n",
    "X_test = pd.read_csv(\"Data/processed/X_test.csv\")\n",
    "y_test = pd.read_csv(\"Data/processed/y_test.csv\").iloc[:, 0]\n",
    "\n",
    "# -------------------------------\n",
    "# 2. Prepare Synthetic Data in Scaled Space\n",
    "# -------------------------------\n",
    "# (Assuming synthetic_num_norm and synthetic_cat are already generated from your diffusion model,\n",
    "# and numeric_features and cat_features are defined as in your preprocessing.)\n",
    "synthetic_num_norm_np = synthetic_num_norm.cpu().numpy()  # scaled numeric features\n",
    "synthetic_numeric_df_scaled = pd.DataFrame(synthetic_num_norm_np, columns=numeric_features)\n",
    "\n",
    "synthetic_cat_np = synthetic_cat.cpu().numpy()\n",
    "synthetic_cat_df = pd.DataFrame(synthetic_cat_np, columns=cat_features)\n",
    "\n",
    "synthetic_scaled_df = pd.concat([synthetic_numeric_df_scaled, synthetic_cat_df], axis=1)\n",
    "synthetic_labels = pd.Series(np.ones(synthetic_scaled_df.shape[0]), name=\"target\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.96615\teval-auc:0.96505\n",
      "[1]\ttrain-auc:0.96624\teval-auc:0.96521\n",
      "[2]\ttrain-auc:0.96629\teval-auc:0.96524\n",
      "[3]\ttrain-auc:0.96609\teval-auc:0.96519\n",
      "[4]\ttrain-auc:0.96727\teval-auc:0.96664\n",
      "[5]\ttrain-auc:0.96759\teval-auc:0.96707\n",
      "[6]\ttrain-auc:0.96809\teval-auc:0.96740\n",
      "[7]\ttrain-auc:0.96811\teval-auc:0.96741\n",
      "[8]\ttrain-auc:0.97283\teval-auc:0.97136\n",
      "[9]\ttrain-auc:0.97320\teval-auc:0.97166\n",
      "[10]\ttrain-auc:0.98194\teval-auc:0.97974\n",
      "[11]\ttrain-auc:0.98222\teval-auc:0.98014\n",
      "[12]\ttrain-auc:0.98264\teval-auc:0.98064\n",
      "[13]\ttrain-auc:0.98313\teval-auc:0.98114\n",
      "[14]\ttrain-auc:0.98342\teval-auc:0.98141\n",
      "[15]\ttrain-auc:0.98404\teval-auc:0.98181\n",
      "[16]\ttrain-auc:0.98424\teval-auc:0.98202\n",
      "[17]\ttrain-auc:0.98452\teval-auc:0.98231\n",
      "[18]\ttrain-auc:0.98473\teval-auc:0.98255\n",
      "[19]\ttrain-auc:0.98489\teval-auc:0.98267\n",
      "[20]\ttrain-auc:0.98511\teval-auc:0.98286\n",
      "[21]\ttrain-auc:0.98556\teval-auc:0.98338\n",
      "[22]\ttrain-auc:0.98570\teval-auc:0.98357\n",
      "[23]\ttrain-auc:0.98590\teval-auc:0.98385\n",
      "[24]\ttrain-auc:0.98693\teval-auc:0.98496\n",
      "[25]\ttrain-auc:0.98724\teval-auc:0.98534\n",
      "[26]\ttrain-auc:0.98760\teval-auc:0.98570\n",
      "[27]\ttrain-auc:0.98770\teval-auc:0.98578\n",
      "[28]\ttrain-auc:0.98831\teval-auc:0.98637\n",
      "[29]\ttrain-auc:0.98866\teval-auc:0.98671\n",
      "[30]\ttrain-auc:0.98872\teval-auc:0.98672\n",
      "[31]\ttrain-auc:0.98917\teval-auc:0.98714\n",
      "[32]\ttrain-auc:0.98942\teval-auc:0.98746\n",
      "[33]\ttrain-auc:0.98962\teval-auc:0.98813\n",
      "[34]\ttrain-auc:0.98965\teval-auc:0.98822\n",
      "[35]\ttrain-auc:0.98955\teval-auc:0.98814\n",
      "[36]\ttrain-auc:0.99119\teval-auc:0.98983\n",
      "[37]\ttrain-auc:0.99194\teval-auc:0.99091\n",
      "[38]\ttrain-auc:0.99248\teval-auc:0.99163\n",
      "[39]\ttrain-auc:0.99303\teval-auc:0.99181\n",
      "[40]\ttrain-auc:0.99333\teval-auc:0.99223\n",
      "[41]\ttrain-auc:0.99356\teval-auc:0.99243\n",
      "[42]\ttrain-auc:0.99366\teval-auc:0.99253\n",
      "[43]\ttrain-auc:0.99383\teval-auc:0.99275\n",
      "[44]\ttrain-auc:0.99446\teval-auc:0.99357\n",
      "[45]\ttrain-auc:0.99468\teval-auc:0.99379\n",
      "[46]\ttrain-auc:0.99479\teval-auc:0.99383\n",
      "[47]\ttrain-auc:0.99491\teval-auc:0.99396\n",
      "[48]\ttrain-auc:0.99491\teval-auc:0.99389\n",
      "[49]\ttrain-auc:0.99499\teval-auc:0.99396\n",
      "[50]\ttrain-auc:0.99510\teval-auc:0.99411\n",
      "[51]\ttrain-auc:0.99522\teval-auc:0.99420\n",
      "[52]\ttrain-auc:0.99548\teval-auc:0.99443\n",
      "[53]\ttrain-auc:0.99562\teval-auc:0.99467\n",
      "[54]\ttrain-auc:0.99562\teval-auc:0.99464\n",
      "[55]\ttrain-auc:0.99564\teval-auc:0.99474\n",
      "[56]\ttrain-auc:0.99584\teval-auc:0.99492\n",
      "[57]\ttrain-auc:0.99587\teval-auc:0.99499\n",
      "[58]\ttrain-auc:0.99592\teval-auc:0.99505\n",
      "[59]\ttrain-auc:0.99594\teval-auc:0.99505\n",
      "[60]\ttrain-auc:0.99594\teval-auc:0.99502\n",
      "[61]\ttrain-auc:0.99605\teval-auc:0.99518\n",
      "[62]\ttrain-auc:0.99612\teval-auc:0.99525\n",
      "[63]\ttrain-auc:0.99621\teval-auc:0.99539\n",
      "[64]\ttrain-auc:0.99625\teval-auc:0.99535\n",
      "[65]\ttrain-auc:0.99633\teval-auc:0.99540\n",
      "[66]\ttrain-auc:0.99629\teval-auc:0.99533\n",
      "[67]\ttrain-auc:0.99642\teval-auc:0.99545\n",
      "[68]\ttrain-auc:0.99649\teval-auc:0.99547\n",
      "[69]\ttrain-auc:0.99648\teval-auc:0.99544\n",
      "[70]\ttrain-auc:0.99659\teval-auc:0.99565\n",
      "[71]\ttrain-auc:0.99669\teval-auc:0.99573\n",
      "[72]\ttrain-auc:0.99676\teval-auc:0.99580\n",
      "[73]\ttrain-auc:0.99690\teval-auc:0.99593\n",
      "[74]\ttrain-auc:0.99695\teval-auc:0.99602\n",
      "[75]\ttrain-auc:0.99700\teval-auc:0.99603\n",
      "[76]\ttrain-auc:0.99720\teval-auc:0.99630\n",
      "[77]\ttrain-auc:0.99723\teval-auc:0.99636\n",
      "[78]\ttrain-auc:0.99737\teval-auc:0.99646\n",
      "[79]\ttrain-auc:0.99745\teval-auc:0.99652\n",
      "[80]\ttrain-auc:0.99749\teval-auc:0.99656\n",
      "[81]\ttrain-auc:0.99753\teval-auc:0.99661\n",
      "[82]\ttrain-auc:0.99757\teval-auc:0.99663\n",
      "[83]\ttrain-auc:0.99764\teval-auc:0.99667\n",
      "[84]\ttrain-auc:0.99768\teval-auc:0.99669\n",
      "[85]\ttrain-auc:0.99780\teval-auc:0.99682\n",
      "[86]\ttrain-auc:0.99785\teval-auc:0.99686\n",
      "[87]\ttrain-auc:0.99789\teval-auc:0.99687\n",
      "[88]\ttrain-auc:0.99798\teval-auc:0.99699\n",
      "[89]\ttrain-auc:0.99802\teval-auc:0.99702\n",
      "[90]\ttrain-auc:0.99805\teval-auc:0.99701\n",
      "[91]\ttrain-auc:0.99808\teval-auc:0.99704\n",
      "[92]\ttrain-auc:0.99813\teval-auc:0.99713\n",
      "[93]\ttrain-auc:0.99817\teval-auc:0.99715\n",
      "[94]\ttrain-auc:0.99819\teval-auc:0.99717\n",
      "[95]\ttrain-auc:0.99822\teval-auc:0.99720\n",
      "[96]\ttrain-auc:0.99831\teval-auc:0.99735\n",
      "[97]\ttrain-auc:0.99834\teval-auc:0.99736\n",
      "[98]\ttrain-auc:0.99835\teval-auc:0.99735\n",
      "[99]\ttrain-auc:0.99837\teval-auc:0.99736\n",
      "Baseline optimal threshold based on F1: 0.2675\n",
      "\n",
      "Baseline Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368549\n",
      "           1       0.93      0.84      0.88      1930\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.96      0.92      0.94    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n",
      "\n",
      "Baseline ROC-AUC: 0.9977005476047173\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 3. Experiment 1: Train XGBoost on Original Data (Baseline)\n",
    "# -------------------------------\n",
    "# Assume X_train_df and y_train_df (with target in first column) are already loaded from your training data.\n",
    "X_train_orig = X_train_df.copy()\n",
    "y_train_orig = y_train_df.iloc[:, 0]\n",
    "\n",
    "# Create DMatrix objects for training, validation, and test sets.\n",
    "dtrain_orig = xgb.DMatrix(X_train_orig, label=y_train_orig)\n",
    "dval = xgb.DMatrix(X_val, label=y_val)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "# XGBoost parameters\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'max_depth': 6,\n",
    "    'eta': 0.1,\n",
    "    'seed': 42\n",
    "}\n",
    "\n",
    "# Train the baseline model\n",
    "watchlist = [(dtrain_orig, 'train'), (dval, 'eval')]\n",
    "model_orig = xgb.train(params, dtrain_orig, num_boost_round=100, evals=watchlist, early_stopping_rounds=10)\n",
    "\n",
    "# Predict on validation and test sets using the baseline model\n",
    "val_pred_proba_baseline = model_orig.predict(dval)\n",
    "test_pred_proba_baseline = model_orig.predict(dtest)\n",
    "\n",
    "# Compute precision, recall and F1 scores on validation set to choose the optimal threshold\n",
    "precision_vals, recall_vals, thresholds = precision_recall_curve(y_val, val_pred_proba_baseline)\n",
    "# Note: thresholds length is one less than precision/recall arrays.\n",
    "f1_scores = 2 * precision_vals[:-1] * recall_vals[:-1] / (precision_vals[:-1] + recall_vals[:-1] + 1e-10)\n",
    "optimal_threshold_baseline = thresholds[np.argmax(f1_scores)]\n",
    "print(f\"Baseline optimal threshold based on F1: {optimal_threshold_baseline:.4f}\")\n",
    "\n",
    "# Apply threshold to test predictions and generate a classification report\n",
    "y_pred_baseline = (test_pred_proba_baseline >= optimal_threshold_baseline).astype(int)\n",
    "print(\"\\nBaseline Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "print(\"Baseline ROC-AUC:\", roc_auc_score(y_test, test_pred_proba_baseline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.88660\teval-auc:0.87265\n",
      "[1]\ttrain-auc:0.91938\teval-auc:0.91787\n",
      "[2]\ttrain-auc:0.91956\teval-auc:0.91797\n",
      "[3]\ttrain-auc:0.92039\teval-auc:0.91913\n",
      "[4]\ttrain-auc:0.94562\teval-auc:0.95099\n",
      "[5]\ttrain-auc:0.94576\teval-auc:0.95111\n",
      "[6]\ttrain-auc:0.94709\teval-auc:0.95124\n",
      "[7]\ttrain-auc:0.94775\teval-auc:0.95220\n",
      "[8]\ttrain-auc:0.96808\teval-auc:0.97208\n",
      "[9]\ttrain-auc:0.96861\teval-auc:0.97265\n",
      "[10]\ttrain-auc:0.96886\teval-auc:0.97298\n",
      "[11]\ttrain-auc:0.96905\teval-auc:0.97323\n",
      "[12]\ttrain-auc:0.96942\teval-auc:0.97365\n",
      "[13]\ttrain-auc:0.97745\teval-auc:0.97827\n",
      "[14]\ttrain-auc:0.97876\teval-auc:0.97860\n",
      "[15]\ttrain-auc:0.98195\teval-auc:0.98093\n",
      "[16]\ttrain-auc:0.98331\teval-auc:0.98272\n",
      "[17]\ttrain-auc:0.98346\teval-auc:0.98281\n",
      "[18]\ttrain-auc:0.98348\teval-auc:0.98279\n",
      "[19]\ttrain-auc:0.98414\teval-auc:0.98332\n",
      "[20]\ttrain-auc:0.98528\teval-auc:0.98482\n",
      "[21]\ttrain-auc:0.98607\teval-auc:0.98600\n",
      "[22]\ttrain-auc:0.98678\teval-auc:0.98677\n",
      "[23]\ttrain-auc:0.98719\teval-auc:0.98719\n",
      "[24]\ttrain-auc:0.98764\teval-auc:0.98769\n",
      "[25]\ttrain-auc:0.98801\teval-auc:0.98802\n",
      "[26]\ttrain-auc:0.98851\teval-auc:0.98836\n",
      "[27]\ttrain-auc:0.98893\teval-auc:0.98882\n",
      "[28]\ttrain-auc:0.98921\teval-auc:0.98903\n",
      "[29]\ttrain-auc:0.98983\teval-auc:0.98932\n",
      "[30]\ttrain-auc:0.99032\teval-auc:0.98963\n",
      "[31]\ttrain-auc:0.99071\teval-auc:0.98950\n",
      "[32]\ttrain-auc:0.99075\teval-auc:0.98954\n",
      "[33]\ttrain-auc:0.99118\teval-auc:0.98999\n",
      "[34]\ttrain-auc:0.99119\teval-auc:0.98992\n",
      "[35]\ttrain-auc:0.99126\teval-auc:0.98994\n",
      "[36]\ttrain-auc:0.99216\teval-auc:0.99117\n",
      "[37]\ttrain-auc:0.99248\teval-auc:0.99159\n",
      "[38]\ttrain-auc:0.99276\teval-auc:0.99178\n",
      "[39]\ttrain-auc:0.99283\teval-auc:0.99169\n",
      "[40]\ttrain-auc:0.99303\teval-auc:0.99182\n",
      "[41]\ttrain-auc:0.99328\teval-auc:0.99213\n",
      "[42]\ttrain-auc:0.99332\teval-auc:0.99208\n",
      "[43]\ttrain-auc:0.99341\teval-auc:0.99215\n",
      "[44]\ttrain-auc:0.99355\teval-auc:0.99228\n",
      "[45]\ttrain-auc:0.99362\teval-auc:0.99230\n",
      "[46]\ttrain-auc:0.99365\teval-auc:0.99226\n",
      "[47]\ttrain-auc:0.99380\teval-auc:0.99244\n",
      "[48]\ttrain-auc:0.99391\teval-auc:0.99249\n",
      "[49]\ttrain-auc:0.99392\teval-auc:0.99245\n",
      "[50]\ttrain-auc:0.99408\teval-auc:0.99248\n",
      "[51]\ttrain-auc:0.99417\teval-auc:0.99258\n",
      "[52]\ttrain-auc:0.99419\teval-auc:0.99254\n",
      "[53]\ttrain-auc:0.99429\teval-auc:0.99256\n",
      "[54]\ttrain-auc:0.99456\teval-auc:0.99258\n",
      "[55]\ttrain-auc:0.99469\teval-auc:0.99266\n",
      "[56]\ttrain-auc:0.99489\teval-auc:0.99274\n",
      "[57]\ttrain-auc:0.99488\teval-auc:0.99267\n",
      "[58]\ttrain-auc:0.99527\teval-auc:0.99273\n",
      "[59]\ttrain-auc:0.99539\teval-auc:0.99279\n",
      "[60]\ttrain-auc:0.99549\teval-auc:0.99289\n",
      "[61]\ttrain-auc:0.99553\teval-auc:0.99296\n",
      "[62]\ttrain-auc:0.99560\teval-auc:0.99305\n",
      "[63]\ttrain-auc:0.99560\teval-auc:0.99301\n",
      "[64]\ttrain-auc:0.99568\teval-auc:0.99303\n",
      "[65]\ttrain-auc:0.99584\teval-auc:0.99309\n",
      "[66]\ttrain-auc:0.99592\teval-auc:0.99320\n",
      "[67]\ttrain-auc:0.99609\teval-auc:0.99316\n",
      "[68]\ttrain-auc:0.99620\teval-auc:0.99336\n",
      "[69]\ttrain-auc:0.99628\teval-auc:0.99341\n",
      "[70]\ttrain-auc:0.99634\teval-auc:0.99353\n",
      "[71]\ttrain-auc:0.99647\teval-auc:0.99354\n",
      "[72]\ttrain-auc:0.99653\teval-auc:0.99358\n",
      "[73]\ttrain-auc:0.99661\teval-auc:0.99359\n",
      "[74]\ttrain-auc:0.99666\teval-auc:0.99365\n",
      "[75]\ttrain-auc:0.99673\teval-auc:0.99369\n",
      "[76]\ttrain-auc:0.99678\teval-auc:0.99383\n",
      "[77]\ttrain-auc:0.99685\teval-auc:0.99392\n",
      "[78]\ttrain-auc:0.99691\teval-auc:0.99397\n",
      "[79]\ttrain-auc:0.99698\teval-auc:0.99399\n",
      "[80]\ttrain-auc:0.99709\teval-auc:0.99419\n",
      "[81]\ttrain-auc:0.99712\teval-auc:0.99427\n",
      "[82]\ttrain-auc:0.99717\teval-auc:0.99429\n",
      "[83]\ttrain-auc:0.99723\teval-auc:0.99431\n",
      "[84]\ttrain-auc:0.99726\teval-auc:0.99441\n",
      "[85]\ttrain-auc:0.99732\teval-auc:0.99442\n",
      "[86]\ttrain-auc:0.99738\teval-auc:0.99454\n",
      "[87]\ttrain-auc:0.99747\teval-auc:0.99463\n",
      "[88]\ttrain-auc:0.99750\teval-auc:0.99465\n",
      "[89]\ttrain-auc:0.99756\teval-auc:0.99478\n",
      "[90]\ttrain-auc:0.99759\teval-auc:0.99483\n",
      "[91]\ttrain-auc:0.99763\teval-auc:0.99487\n",
      "[92]\ttrain-auc:0.99768\teval-auc:0.99490\n",
      "[93]\ttrain-auc:0.99770\teval-auc:0.99491\n",
      "[94]\ttrain-auc:0.99773\teval-auc:0.99493\n",
      "[95]\ttrain-auc:0.99775\teval-auc:0.99497\n",
      "[96]\ttrain-auc:0.99780\teval-auc:0.99509\n",
      "[97]\ttrain-auc:0.99782\teval-auc:0.99513\n",
      "[98]\ttrain-auc:0.99791\teval-auc:0.99536\n",
      "[99]\ttrain-auc:0.99793\teval-auc:0.99539\n",
      "\n",
      "Combined optimal threshold based on F1: 0.3389\n",
      "\n",
      "Combined Model Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    368549\n",
      "           1       0.93      0.80      0.86      1930\n",
      "\n",
      "    accuracy                           1.00    370479\n",
      "   macro avg       0.96      0.90      0.93    370479\n",
      "weighted avg       1.00      1.00      1.00    370479\n",
      "\n",
      "Combined ROC-AUC: 0.9964593124947341\n"
     ]
    }
   ],
   "source": [
    "# -------------------------------\n",
    "# 4. Experiment 2: Train XGBoost on Combined Data (Original + Synthetic Fraud Samples)\n",
    "# -------------------------------\n",
    "X_train_combined = pd.concat([X_train_orig, synthetic_scaled_df], ignore_index=True)\n",
    "y_train_combined = pd.concat([y_train_orig, synthetic_labels], ignore_index=True)\n",
    "\n",
    "dtrain_combined = xgb.DMatrix(X_train_combined, label=y_train_combined)\n",
    "\n",
    "watchlist_combined = [(dtrain_combined, 'train'), (dval, 'eval')]\n",
    "model_combined = xgb.train(params, dtrain_combined, num_boost_round=100, evals=watchlist_combined, early_stopping_rounds=10)\n",
    "\n",
    "# Predict on validation and test sets using the combined model\n",
    "val_pred_proba_combined = model_combined.predict(dval)\n",
    "test_pred_proba_combined = model_combined.predict(dtest)\n",
    "\n",
    "precision_vals_c, recall_vals_c, thresholds_c = precision_recall_curve(y_val, val_pred_proba_combined)\n",
    "f1_scores_c = 2 * precision_vals_c[:-1] * recall_vals_c[:-1] / (precision_vals_c[:-1] + recall_vals_c[:-1] + 1e-10)\n",
    "optimal_threshold_combined = thresholds_c[np.argmax(f1_scores_c)]\n",
    "print(f\"\\nCombined optimal threshold based on F1: {optimal_threshold_combined:.4f}\")\n",
    "\n",
    "# Apply threshold to test predictions and generate a classification report\n",
    "y_pred_combined = (test_pred_proba_combined >= optimal_threshold_combined).astype(int)\n",
    "print(\"\\nCombined Model Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_combined))\n",
    "print(\"Combined ROC-AUC:\", roc_auc_score(y_test, test_pred_proba_combined))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
