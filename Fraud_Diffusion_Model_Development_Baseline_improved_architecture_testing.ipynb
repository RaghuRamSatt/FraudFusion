{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Architectural Hyperparameter Tuning\n",
    "# Focus: hidden_dim, num_layers, activation, optimizer_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Step 1: Data and Fixed Parameters\n",
    "#############################################\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"True\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import joblib\n",
    "from scipy.stats import wasserstein_distance\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from itertools import product\n",
    "\n",
    "# Load data and artifacts\n",
    "X_train_df = pd.read_csv(r\"D:\\DS Northeastern\\DS 5500 - Capstone\\FraudFusion\\Data\\processed\\X_train.csv\")\n",
    "y_train_df = pd.read_csv(r\"D:\\DS Northeastern\\DS 5500 - Capstone\\FraudFusion\\Data\\processed\\y_train.csv\")\n",
    "scaler = joblib.load(r\"D:\\DS Northeastern\\DS 5500 - Capstone\\FraudFusion\\Data\\processed\\standard_scaler.pkl\")\n",
    "cat_vocab = joblib.load(r\"D:\\DS Northeastern\\DS 5500 - Capstone\\FraudFusion\\Data\\processed\\cat_vocab.pkl\")\n",
    "\n",
    "# Fixed parameters from best configuration\n",
    "FIXED_PARAMS = {\n",
    "    'w1': 0.2, 'w2': 0.55, 'lambda_eng': 0.15,\n",
    "    'lr': 0.001, 'batch_size': 40, 'T_train': 800\n",
    "}\n",
    "\n",
    "# Feature setup\n",
    "numeric_features = ['amt', 'lat', 'long', 'city_pop', 'merch_lat', 'merch_long',\n",
    "                    'age', 'trans_hour', 'trans_day', 'trans_month', 'trans_dayofweek']\n",
    "cat_features = ['merchant', 'category', 'gender', 'street', 'city', 'state', 'zip', 'job']\n",
    "eng_indices = [numeric_features.index(f) for f in ['trans_hour', 'trans_day', 'trans_month', 'trans_dayofweek']]\n",
    "\n",
    "# Filter and prepare data\n",
    "fraud_mask = (y_train_df.iloc[:, 0] == 1)\n",
    "X_train_num = X_train_df[numeric_features].loc[fraud_mask].values\n",
    "X_train_cat = X_train_df[cat_features].loc[fraud_mask].values\n",
    "X_nonfraud_num = X_train_df[numeric_features].loc[~fraud_mask].values\n",
    "\n",
    "# Engineered feature constraints\n",
    "eng_min = torch.tensor(np.min(X_train_num[:, eng_indices], axis=0), \n",
    "                      dtype=torch.float32, device='cuda' if torch.cuda.is_available() else 'cpu')\n",
    "eng_max = torch.tensor(np.max(X_train_num[:, eng_indices], axis=0),\n",
    "                     dtype=torch.float32, device='cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Step 2: Dataset and Model Setup\n",
    "#############################################\n",
    "class FraudDataset(Dataset):\n",
    "    def __init__(self, num_data, cat_data):\n",
    "        self.num_data = torch.tensor(num_data, dtype=torch.float32)\n",
    "        self.cat_data = torch.tensor(cat_data, dtype=torch.long)\n",
    "    def __len__(self): return len(self.num_data)\n",
    "    def __getitem__(self, idx): return self.num_data[idx], self.cat_data[idx]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "beta = torch.linspace(1e-4, 0.02, FIXED_PARAMS['T_train']).to(device)\n",
    "alpha = 1 - beta\n",
    "alpha_hat = torch.cumprod(alpha, dim=0)\n",
    "X_nonfraud_tensor = torch.tensor(X_nonfraud_num, dtype=torch.float32).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Step 3: Model Architecture\n",
    "#############################################\n",
    "class AdvancedNoisePredictor(nn.Module):\n",
    "    def __init__(self, num_input_dim, cat_vocab_sizes, \n",
    "                 hidden_dim=256, num_layers=2, \n",
    "                 activation='LeakyReLU', cat_embed_dim=2):\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.ModuleDict()\n",
    "        for col, vocab_size in cat_vocab_sizes.items():\n",
    "            self.embeddings[col] = nn.Embedding(vocab_size, cat_embed_dim)\n",
    "        \n",
    "        cat_total_dim = len(cat_vocab_sizes) * cat_embed_dim\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(num_input_dim + cat_total_dim + 1, hidden_dim),\n",
    "            self._get_activation(activation),\n",
    "            *[nn.Sequential(\n",
    "                nn.Linear(hidden_dim, hidden_dim),\n",
    "                self._get_activation(activation)\n",
    "              ) for _ in range(num_layers-1)],\n",
    "            nn.Linear(hidden_dim, num_input_dim)\n",
    "        )\n",
    "\n",
    "    def _get_activation(self, name):\n",
    "        return {'LeakyReLU': nn.LeakyReLU(), 'GELU': nn.GELU()}[name]\n",
    "\n",
    "    def forward(self, x_num, x_cat, t):\n",
    "        embeds = [self.embeddings[col](x_cat[:,i]) for i,col in enumerate(self.embeddings)]\n",
    "        x = torch.cat([x_num, *embeds, (t.float()/FIXED_PARAMS['T_train']).unsqueeze(1)], dim=1)\n",
    "        return self.mlp(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Step 4: Training Infrastructure\n",
    "#############################################\n",
    "def forward_diffusion(x0, t):\n",
    "    sqrt_alpha_hat_t = torch.sqrt(alpha_hat[t]).unsqueeze(1)\n",
    "    sqrt_one_minus_alpha_hat_t = torch.sqrt(1 - alpha_hat[t]).unsqueeze(1)\n",
    "    noise = torch.randn_like(x0)\n",
    "    return sqrt_alpha_hat_t * x0 + sqrt_one_minus_alpha_hat_t * noise, noise\n",
    "\n",
    "def train_arch_config(config):\n",
    "    model = AdvancedNoisePredictor(\n",
    "        num_input_dim=len(numeric_features),\n",
    "        cat_vocab_sizes={col: cat_vocab[col] for col in cat_features},\n",
    "        hidden_dim=config['hidden_dim'],\n",
    "        num_layers=config['num_layers'],\n",
    "        activation=config['activation']\n",
    "    ).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=FIXED_PARAMS['lr']) if config['optimizer_type'] == 'Adam' else \\\n",
    "               optim.AdamW(model.parameters(), lr=FIXED_PARAMS['lr'])\n",
    "    \n",
    "    train_loader = DataLoader(FraudDataset(X_train_num, X_train_cat), \n",
    "                             batch_size=FIXED_PARAMS['batch_size'], shuffle=True)\n",
    "    \n",
    "    mu_nf = X_nonfraud_tensor.mean(dim=0)\n",
    "    sigma_nf = X_nonfraud_tensor.std(dim=0) + 1e-5\n",
    "    loss_components = {'total': [], 'mse': [], 'prior': [], 'triplet': [], 'eng': []}\n",
    "\n",
    "    for epoch in range(150):\n",
    "        model.train()\n",
    "        epoch_losses = [0]*5  # total, mse, prior, triplet, eng\n",
    "        \n",
    "        for x_num, x_cat in train_loader:\n",
    "            x_num, x_cat = x_num.to(device), x_cat.to(device)\n",
    "            t = torch.randint(0, FIXED_PARAMS['T_train'], (x_num.size(0),), device=device)\n",
    "            \n",
    "            x_t, noise = forward_diffusion(x_num, t)\n",
    "            pred_noise = model(x_t, x_cat, t)\n",
    "            \n",
    "            # Calculate losses\n",
    "            mse_loss = F.mse_loss(pred_noise, noise)\n",
    "            z = (pred_noise - mu_nf)/sigma_nf\n",
    "            prior_loss = (1 - 2*(1 - torch.distributions.Normal(0,1).cdf(torch.abs(z)))).mean()\n",
    "            x0_est = (x_t - torch.sqrt(1-alpha_hat[t]).unsqueeze(1)*pred_noise)/torch.sqrt(alpha_hat[t]).unsqueeze(1)\n",
    "            rand_idx = torch.randint(0, len(X_nonfraud_tensor), (x_num.size(0),))\n",
    "            triplet_loss = F.relu(F.pairwise_distance(x0_est, x_num) - \n",
    "                                 F.pairwise_distance(x0_est, X_nonfraud_tensor[rand_idx]) + 1).mean()\n",
    "            eng_loss = torch.mean(F.relu(eng_min - x0_est[:,eng_indices]) + \n",
    "                                F.relu(x0_est[:,eng_indices] - eng_max))\n",
    "            \n",
    "            total_loss = (mse_loss + FIXED_PARAMS['w1']*prior_loss + \n",
    "                        FIXED_PARAMS['w2']*triplet_loss + FIXED_PARAMS['lambda_eng']*eng_loss)\n",
    "            \n",
    "            # Optimization step\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Accumulate losses\n",
    "            losses = [total_loss.item(), mse_loss.item(), prior_loss.item(), \n",
    "                     triplet_loss.item(), eng_loss.item()]\n",
    "            for i in range(5): epoch_losses[i] += losses[i]\n",
    "        \n",
    "        # Store and print metrics\n",
    "        batches = len(train_loader)\n",
    "        for i, key in enumerate(loss_components): \n",
    "            loss_components[key].append(epoch_losses[i]/batches)\n",
    "            \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/150 | \"\n",
    "                  f\"Total: {loss_components['total'][-1]:.4f} | \"\n",
    "                  f\"MSE: {loss_components['mse'][-1]:.4f} | \"\n",
    "                  f\"Prior: {loss_components['prior'][-1]:.4f} | \"\n",
    "                  f\"Triplet: {loss_components['triplet'][-1]:.4f} | \"\n",
    "                  f\"Eng: {loss_components['eng'][-1]:.4f}\")\n",
    "    \n",
    "    return model, loss_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# Step 5: Evaluation & Visualization\n",
    "#############################################\n",
    "def generate_categorical_samples(num_samples):\n",
    "    synthetic_cat = {}\n",
    "    for col in cat_features:\n",
    "        value_counts = pd.Series(X_train_cat[:, cat_features.index(col)]).value_counts(normalize=True)\n",
    "        synthetic_cat[col] = np.random.choice(value_counts.index, size=num_samples, p=value_counts.values)\n",
    "    return torch.tensor(pd.DataFrame(synthetic_cat).values, dtype=torch.long)\n",
    "\n",
    "def generate_samples(model, num_samples=1000):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        synthetic_cat = generate_categorical_samples(num_samples).to(device)\n",
    "        x_num = torch.randn(num_samples, len(numeric_features)).to(device)\n",
    "        \n",
    "        for t in reversed(range(FIXED_PARAMS['T_train'])):\n",
    "            t_tensor = torch.full((num_samples,), t, device=device)\n",
    "            pred_noise = model(x_num, synthetic_cat, t_tensor)\n",
    "            beta_t = beta[t].view(1,1)\n",
    "            sqrt_alpha_t = torch.sqrt(1 - beta_t)\n",
    "            x_num = (x_num - beta_t*pred_noise/(torch.sqrt(1 - alpha_hat[t])))/sqrt_alpha_t\n",
    "            if t > 0: x_num += torch.sqrt(beta_t)*torch.randn_like(x_num)\n",
    "        \n",
    "        x_num[:, eng_indices] = torch.clamp(x_num[:, eng_indices], eng_min, eng_max)\n",
    "        return x_num.cpu().numpy()\n",
    "\n",
    "def evaluate_model(model):\n",
    "    synthetic_num = scaler.inverse_transform(generate_samples(model))\n",
    "    real_num = scaler.inverse_transform(X_train_num)\n",
    "    return np.mean([wasserstein_distance(real_num[:,i], synthetic_num[:,i]) \n",
    "                  for i in range(len(numeric_features))])\n",
    "\n",
    "def plot_results(results):\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    # Training curves\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for res in results:\n",
    "        label = f\"HD{res['hidden_dim']}-L{res['num_layers']}-{res['activation'][:4]}-{res['optimizer_type']}\"\n",
    "        plt.plot(res['loss_components']['total'], label=label)\n",
    "    plt.title(\"Training Loss Curves\")\n",
    "    plt.xlabel(\"Epoch\"), plt.ylabel(\"Loss\")\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1)), plt.grid(True)\n",
    "    \n",
    "    # Performance comparison\n",
    "    plt.subplot(1, 2, 2)\n",
    "    config_labels = [f\"HD{r['hidden_dim']}-L{r['num_layers']}\" for r in results]\n",
    "    wassersteins = [r['wasserstein'] for r in results]\n",
    "    plt.barh(config_labels, wassersteins)\n",
    "    plt.title(\"Wasserstein Distance by Architecture\")\n",
    "    plt.xlabel(\"Distance\"), plt.ylabel(\"Configuration\")\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5526 | MSE: 0.3372 | Prior: 0.4276 | Triplet: 0.1458 | Eng: 0.3314\n",
      "Epoch 20/150 | Total: 0.4805 | MSE: 0.3001 | Prior: 0.4225 | Triplet: 0.1000 | Eng: 0.2732\n",
      "Epoch 30/150 | Total: 0.4221 | MSE: 0.2617 | Prior: 0.4233 | Triplet: 0.0784 | Eng: 0.2173\n",
      "Epoch 40/150 | Total: 0.3950 | MSE: 0.2414 | Prior: 0.4222 | Triplet: 0.0716 | Eng: 0.1986\n",
      "Epoch 50/150 | Total: 0.3654 | MSE: 0.2258 | Prior: 0.4280 | Triplet: 0.0568 | Eng: 0.1520\n",
      "Epoch 60/150 | Total: 0.3598 | MSE: 0.2173 | Prior: 0.4299 | Triplet: 0.0566 | Eng: 0.1694\n",
      "Epoch 70/150 | Total: 0.3450 | MSE: 0.2123 | Prior: 0.4302 | Triplet: 0.0494 | Eng: 0.1299\n",
      "Epoch 80/150 | Total: 0.3293 | MSE: 0.2010 | Prior: 0.4359 | Triplet: 0.0401 | Eng: 0.1271\n",
      "Epoch 90/150 | Total: 0.3221 | MSE: 0.1960 | Prior: 0.4335 | Triplet: 0.0402 | Eng: 0.1150\n",
      "Epoch 100/150 | Total: 0.3137 | MSE: 0.1894 | Prior: 0.4357 | Triplet: 0.0377 | Eng: 0.1092\n",
      "Epoch 110/150 | Total: 0.3033 | MSE: 0.1806 | Prior: 0.4387 | Triplet: 0.0322 | Eng: 0.1150\n",
      "Epoch 120/150 | Total: 0.3021 | MSE: 0.1765 | Prior: 0.4412 | Triplet: 0.0378 | Eng: 0.1107\n",
      "Epoch 130/150 | Total: 0.2850 | MSE: 0.1658 | Prior: 0.4436 | Triplet: 0.0314 | Eng: 0.0882\n",
      "Epoch 140/150 | Total: 0.2887 | MSE: 0.1693 | Prior: 0.4427 | Triplet: 0.0327 | Eng: 0.0852\n",
      "Epoch 150/150 | Total: 0.2820 | MSE: 0.1648 | Prior: 0.4420 | Triplet: 0.0321 | Eng: 0.0749\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2820\n",
      "  Min Loss: 0.2744\n",
      "  Wasserstein: 0.5961\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5658 | MSE: 0.3360 | Prior: 0.4320 | Triplet: 0.1664 | Eng: 0.3459\n",
      "Epoch 20/150 | Total: 0.4850 | MSE: 0.2983 | Prior: 0.4206 | Triplet: 0.1137 | Eng: 0.2673\n",
      "Epoch 30/150 | Total: 0.4436 | MSE: 0.2794 | Prior: 0.4214 | Triplet: 0.0892 | Eng: 0.2058\n",
      "Epoch 40/150 | Total: 0.4071 | MSE: 0.2535 | Prior: 0.4224 | Triplet: 0.0761 | Eng: 0.1818\n",
      "Epoch 50/150 | Total: 0.3856 | MSE: 0.2370 | Prior: 0.4232 | Triplet: 0.0677 | Eng: 0.1783\n",
      "Epoch 60/150 | Total: 0.3625 | MSE: 0.2258 | Prior: 0.4281 | Triplet: 0.0551 | Eng: 0.1379\n",
      "Epoch 70/150 | Total: 0.3508 | MSE: 0.2144 | Prior: 0.4300 | Triplet: 0.0544 | Eng: 0.1370\n",
      "Epoch 80/150 | Total: 0.3363 | MSE: 0.2090 | Prior: 0.4331 | Triplet: 0.0441 | Eng: 0.1092\n",
      "Epoch 90/150 | Total: 0.3150 | MSE: 0.1883 | Prior: 0.4366 | Triplet: 0.0396 | Eng: 0.1170\n",
      "Epoch 100/150 | Total: 0.3212 | MSE: 0.1973 | Prior: 0.4389 | Triplet: 0.0349 | Eng: 0.1132\n",
      "Epoch 110/150 | Total: 0.3000 | MSE: 0.1780 | Prior: 0.4415 | Triplet: 0.0341 | Eng: 0.0996\n",
      "Epoch 120/150 | Total: 0.2961 | MSE: 0.1746 | Prior: 0.4425 | Triplet: 0.0352 | Eng: 0.0911\n",
      "Epoch 130/150 | Total: 0.2889 | MSE: 0.1692 | Prior: 0.4421 | Triplet: 0.0299 | Eng: 0.0990\n",
      "Epoch 140/150 | Total: 0.2884 | MSE: 0.1704 | Prior: 0.4438 | Triplet: 0.0299 | Eng: 0.0850\n",
      "Epoch 150/150 | Total: 0.2800 | MSE: 0.1632 | Prior: 0.4453 | Triplet: 0.0306 | Eng: 0.0726\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2800\n",
      "  Min Loss: 0.2736\n",
      "  Wasserstein: 0.7371\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5284 | MSE: 0.3270 | Prior: 0.4247 | Triplet: 0.1481 | Eng: 0.2333\n",
      "Epoch 20/150 | Total: 0.4477 | MSE: 0.2820 | Prior: 0.4238 | Triplet: 0.0966 | Eng: 0.1853\n",
      "Epoch 30/150 | Total: 0.4103 | MSE: 0.2568 | Prior: 0.4259 | Triplet: 0.0788 | Eng: 0.1666\n",
      "Epoch 40/150 | Total: 0.3863 | MSE: 0.2473 | Prior: 0.4261 | Triplet: 0.0593 | Eng: 0.1414\n",
      "Epoch 50/150 | Total: 0.3613 | MSE: 0.2238 | Prior: 0.4272 | Triplet: 0.0584 | Eng: 0.1333\n",
      "Epoch 60/150 | Total: 0.3476 | MSE: 0.2195 | Prior: 0.4280 | Triplet: 0.0473 | Eng: 0.1100\n",
      "Epoch 70/150 | Total: 0.3304 | MSE: 0.2075 | Prior: 0.4313 | Triplet: 0.0383 | Eng: 0.1042\n",
      "Epoch 80/150 | Total: 0.3233 | MSE: 0.2026 | Prior: 0.4314 | Triplet: 0.0367 | Eng: 0.0949\n",
      "Epoch 90/150 | Total: 0.3137 | MSE: 0.1908 | Prior: 0.4388 | Triplet: 0.0331 | Eng: 0.1127\n",
      "Epoch 100/150 | Total: 0.3048 | MSE: 0.1850 | Prior: 0.4378 | Triplet: 0.0342 | Eng: 0.0896\n",
      "Epoch 110/150 | Total: 0.3010 | MSE: 0.1791 | Prior: 0.4413 | Triplet: 0.0341 | Eng: 0.0988\n",
      "Epoch 120/150 | Total: 0.2902 | MSE: 0.1708 | Prior: 0.4432 | Triplet: 0.0311 | Eng: 0.0906\n",
      "Epoch 130/150 | Total: 0.2815 | MSE: 0.1654 | Prior: 0.4418 | Triplet: 0.0286 | Eng: 0.0800\n",
      "Epoch 140/150 | Total: 0.2722 | MSE: 0.1571 | Prior: 0.4441 | Triplet: 0.0260 | Eng: 0.0796\n",
      "Epoch 150/150 | Total: 0.2760 | MSE: 0.1570 | Prior: 0.4450 | Triplet: 0.0310 | Eng: 0.0858\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2760\n",
      "  Min Loss: 0.2688\n",
      "  Wasserstein: 0.7489\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5328 | MSE: 0.3307 | Prior: 0.4225 | Triplet: 0.1414 | Eng: 0.2659\n",
      "Epoch 20/150 | Total: 0.4629 | MSE: 0.2919 | Prior: 0.4210 | Triplet: 0.1027 | Eng: 0.2020\n",
      "Epoch 30/150 | Total: 0.4161 | MSE: 0.2662 | Prior: 0.4220 | Triplet: 0.0775 | Eng: 0.1528\n",
      "Epoch 40/150 | Total: 0.3813 | MSE: 0.2417 | Prior: 0.4241 | Triplet: 0.0609 | Eng: 0.1419\n",
      "Epoch 50/150 | Total: 0.3628 | MSE: 0.2354 | Prior: 0.4242 | Triplet: 0.0482 | Eng: 0.1068\n",
      "Epoch 60/150 | Total: 0.3409 | MSE: 0.2130 | Prior: 0.4324 | Triplet: 0.0416 | Eng: 0.1239\n",
      "Epoch 70/150 | Total: 0.3301 | MSE: 0.2058 | Prior: 0.4327 | Triplet: 0.0385 | Eng: 0.1108\n",
      "Epoch 80/150 | Total: 0.3209 | MSE: 0.1993 | Prior: 0.4329 | Triplet: 0.0366 | Eng: 0.0989\n",
      "Epoch 90/150 | Total: 0.3146 | MSE: 0.1934 | Prior: 0.4352 | Triplet: 0.0338 | Eng: 0.1040\n",
      "Epoch 100/150 | Total: 0.3036 | MSE: 0.1840 | Prior: 0.4382 | Triplet: 0.0311 | Eng: 0.0992\n",
      "Epoch 110/150 | Total: 0.2977 | MSE: 0.1799 | Prior: 0.4380 | Triplet: 0.0292 | Eng: 0.0938\n",
      "Epoch 120/150 | Total: 0.2872 | MSE: 0.1710 | Prior: 0.4404 | Triplet: 0.0260 | Eng: 0.0927\n",
      "Epoch 130/150 | Total: 0.2786 | MSE: 0.1632 | Prior: 0.4436 | Triplet: 0.0258 | Eng: 0.0835\n",
      "Epoch 140/150 | Total: 0.2742 | MSE: 0.1586 | Prior: 0.4423 | Triplet: 0.0278 | Eng: 0.0787\n",
      "Epoch 150/150 | Total: 0.2743 | MSE: 0.1577 | Prior: 0.4435 | Triplet: 0.0275 | Eng: 0.0854\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2743\n",
      "  Min Loss: 0.2691\n",
      "  Wasserstein: 0.6120\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5858 | MSE: 0.3397 | Prior: 0.4170 | Triplet: 0.1717 | Eng: 0.4558\n",
      "Epoch 20/150 | Total: 0.5126 | MSE: 0.3087 | Prior: 0.4111 | Triplet: 0.1288 | Eng: 0.3395\n",
      "Epoch 30/150 | Total: 0.4485 | MSE: 0.2744 | Prior: 0.4198 | Triplet: 0.0902 | Eng: 0.2700\n",
      "Epoch 40/150 | Total: 0.4276 | MSE: 0.2629 | Prior: 0.4206 | Triplet: 0.0761 | Eng: 0.2582\n",
      "Epoch 50/150 | Total: 0.4070 | MSE: 0.2478 | Prior: 0.4261 | Triplet: 0.0672 | Eng: 0.2465\n",
      "Epoch 60/150 | Total: 0.3897 | MSE: 0.2329 | Prior: 0.4311 | Triplet: 0.0666 | Eng: 0.2268\n",
      "Epoch 70/150 | Total: 0.3735 | MSE: 0.2256 | Prior: 0.4317 | Triplet: 0.0546 | Eng: 0.2099\n",
      "Epoch 80/150 | Total: 0.3446 | MSE: 0.2067 | Prior: 0.4358 | Triplet: 0.0450 | Eng: 0.1734\n",
      "Epoch 90/150 | Total: 0.3424 | MSE: 0.2020 | Prior: 0.4384 | Triplet: 0.0435 | Eng: 0.1922\n",
      "Epoch 100/150 | Total: 0.3330 | MSE: 0.1977 | Prior: 0.4400 | Triplet: 0.0388 | Eng: 0.1731\n",
      "Epoch 110/150 | Total: 0.3205 | MSE: 0.1864 | Prior: 0.4368 | Triplet: 0.0400 | Eng: 0.1655\n",
      "Epoch 120/150 | Total: 0.3071 | MSE: 0.1713 | Prior: 0.4449 | Triplet: 0.0394 | Eng: 0.1674\n",
      "Epoch 130/150 | Total: 0.3054 | MSE: 0.1750 | Prior: 0.4425 | Triplet: 0.0380 | Eng: 0.1400\n",
      "Epoch 140/150 | Total: 0.2946 | MSE: 0.1644 | Prior: 0.4471 | Triplet: 0.0364 | Eng: 0.1382\n",
      "Epoch 150/150 | Total: 0.2965 | MSE: 0.1665 | Prior: 0.4473 | Triplet: 0.0353 | Eng: 0.1409\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2965\n",
      "  Min Loss: 0.2913\n",
      "  Wasserstein: 0.7204\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.6064 | MSE: 0.3470 | Prior: 0.4181 | Triplet: 0.1794 | Eng: 0.5141\n",
      "Epoch 20/150 | Total: 0.4831 | MSE: 0.2909 | Prior: 0.4130 | Triplet: 0.1127 | Eng: 0.3170\n",
      "Epoch 30/150 | Total: 0.4405 | MSE: 0.2667 | Prior: 0.4199 | Triplet: 0.0891 | Eng: 0.2723\n",
      "Epoch 40/150 | Total: 0.4134 | MSE: 0.2446 | Prior: 0.4268 | Triplet: 0.0749 | Eng: 0.2819\n",
      "Epoch 50/150 | Total: 0.3893 | MSE: 0.2330 | Prior: 0.4289 | Triplet: 0.0628 | Eng: 0.2401\n",
      "Epoch 60/150 | Total: 0.3813 | MSE: 0.2258 | Prior: 0.4310 | Triplet: 0.0566 | Eng: 0.2543\n",
      "Epoch 70/150 | Total: 0.3597 | MSE: 0.2208 | Prior: 0.4308 | Triplet: 0.0466 | Eng: 0.1806\n",
      "Epoch 80/150 | Total: 0.3487 | MSE: 0.2030 | Prior: 0.4356 | Triplet: 0.0461 | Eng: 0.2212\n",
      "Epoch 90/150 | Total: 0.3393 | MSE: 0.1984 | Prior: 0.4388 | Triplet: 0.0425 | Eng: 0.1988\n",
      "Epoch 100/150 | Total: 0.3216 | MSE: 0.1872 | Prior: 0.4420 | Triplet: 0.0377 | Eng: 0.1686\n",
      "Epoch 110/150 | Total: 0.3114 | MSE: 0.1818 | Prior: 0.4423 | Triplet: 0.0355 | Eng: 0.1441\n",
      "Epoch 120/150 | Total: 0.3138 | MSE: 0.1780 | Prior: 0.4410 | Triplet: 0.0380 | Eng: 0.1782\n",
      "Epoch 130/150 | Total: 0.3027 | MSE: 0.1715 | Prior: 0.4443 | Triplet: 0.0336 | Eng: 0.1585\n",
      "Epoch 140/150 | Total: 0.3014 | MSE: 0.1724 | Prior: 0.4434 | Triplet: 0.0341 | Eng: 0.1438\n",
      "Epoch 150/150 | Total: 0.2864 | MSE: 0.1592 | Prior: 0.4473 | Triplet: 0.0325 | Eng: 0.1318\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2864\n",
      "  Min Loss: 0.2850\n",
      "  Wasserstein: 0.9975\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5331 | MSE: 0.3186 | Prior: 0.4210 | Triplet: 0.1433 | Eng: 0.3429\n",
      "Epoch 20/150 | Total: 0.4427 | MSE: 0.2755 | Prior: 0.4149 | Triplet: 0.0938 | Eng: 0.2173\n",
      "Epoch 30/150 | Total: 0.4147 | MSE: 0.2566 | Prior: 0.4208 | Triplet: 0.0731 | Eng: 0.2249\n",
      "Epoch 40/150 | Total: 0.3917 | MSE: 0.2412 | Prior: 0.4249 | Triplet: 0.0648 | Eng: 0.1989\n",
      "Epoch 50/150 | Total: 0.3811 | MSE: 0.2352 | Prior: 0.4242 | Triplet: 0.0591 | Eng: 0.1907\n",
      "Epoch 60/150 | Total: 0.3630 | MSE: 0.2175 | Prior: 0.4298 | Triplet: 0.0519 | Eng: 0.2067\n",
      "Epoch 70/150 | Total: 0.3448 | MSE: 0.2099 | Prior: 0.4337 | Triplet: 0.0450 | Eng: 0.1563\n",
      "Epoch 80/150 | Total: 0.3446 | MSE: 0.2066 | Prior: 0.4366 | Triplet: 0.0438 | Eng: 0.1774\n",
      "Epoch 90/150 | Total: 0.3229 | MSE: 0.1948 | Prior: 0.4398 | Triplet: 0.0336 | Eng: 0.1445\n",
      "Epoch 100/150 | Total: 0.3176 | MSE: 0.1865 | Prior: 0.4423 | Triplet: 0.0383 | Eng: 0.1439\n",
      "Epoch 110/150 | Total: 0.3087 | MSE: 0.1768 | Prior: 0.4445 | Triplet: 0.0381 | Eng: 0.1468\n",
      "Epoch 120/150 | Total: 0.2972 | MSE: 0.1693 | Prior: 0.4465 | Triplet: 0.0304 | Eng: 0.1464\n",
      "Epoch 130/150 | Total: 0.2943 | MSE: 0.1686 | Prior: 0.4461 | Triplet: 0.0273 | Eng: 0.1432\n",
      "Epoch 140/150 | Total: 0.2840 | MSE: 0.1595 | Prior: 0.4477 | Triplet: 0.0306 | Eng: 0.1205\n",
      "Epoch 150/150 | Total: 0.2872 | MSE: 0.1620 | Prior: 0.4497 | Triplet: 0.0300 | Eng: 0.1251\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2872\n",
      "  Min Loss: 0.2793\n",
      "  Wasserstein: 0.7166\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 224, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5362 | MSE: 0.3213 | Prior: 0.4137 | Triplet: 0.1463 | Eng: 0.3442\n",
      "Epoch 20/150 | Total: 0.4630 | MSE: 0.2839 | Prior: 0.4155 | Triplet: 0.1095 | Eng: 0.2388\n",
      "Epoch 30/150 | Total: 0.4136 | MSE: 0.2558 | Prior: 0.4217 | Triplet: 0.0760 | Eng: 0.2108\n",
      "Epoch 40/150 | Total: 0.3986 | MSE: 0.2513 | Prior: 0.4200 | Triplet: 0.0619 | Eng: 0.1951\n",
      "Epoch 50/150 | Total: 0.3845 | MSE: 0.2382 | Prior: 0.4258 | Triplet: 0.0584 | Eng: 0.1936\n",
      "Epoch 60/150 | Total: 0.3564 | MSE: 0.2192 | Prior: 0.4318 | Triplet: 0.0439 | Eng: 0.1779\n",
      "Epoch 70/150 | Total: 0.3434 | MSE: 0.2097 | Prior: 0.4315 | Triplet: 0.0409 | Eng: 0.1664\n",
      "Epoch 80/150 | Total: 0.3323 | MSE: 0.1990 | Prior: 0.4371 | Triplet: 0.0397 | Eng: 0.1606\n",
      "Epoch 90/150 | Total: 0.3181 | MSE: 0.1909 | Prior: 0.4373 | Triplet: 0.0331 | Eng: 0.1440\n",
      "Epoch 100/150 | Total: 0.3110 | MSE: 0.1813 | Prior: 0.4430 | Triplet: 0.0336 | Eng: 0.1512\n",
      "Epoch 110/150 | Total: 0.2997 | MSE: 0.1729 | Prior: 0.4421 | Triplet: 0.0337 | Eng: 0.1326\n",
      "Epoch 120/150 | Total: 0.2989 | MSE: 0.1703 | Prior: 0.4475 | Triplet: 0.0333 | Eng: 0.1381\n",
      "Epoch 130/150 | Total: 0.2885 | MSE: 0.1633 | Prior: 0.4478 | Triplet: 0.0291 | Eng: 0.1308\n",
      "Epoch 140/150 | Total: 0.2822 | MSE: 0.1600 | Prior: 0.4455 | Triplet: 0.0296 | Eng: 0.1125\n",
      "Epoch 150/150 | Total: 0.2794 | MSE: 0.1557 | Prior: 0.4476 | Triplet: 0.0305 | Eng: 0.1162\n",
      "\n",
      "Results for {'hidden_dim': 224, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2794\n",
      "  Min Loss: 0.2794\n",
      "  Wasserstein: 0.6416\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5724 | MSE: 0.3428 | Prior: 0.4209 | Triplet: 0.1561 | Eng: 0.3968\n",
      "Epoch 20/150 | Total: 0.4755 | MSE: 0.2951 | Prior: 0.4188 | Triplet: 0.0968 | Eng: 0.2894\n",
      "Epoch 30/150 | Total: 0.4268 | MSE: 0.2686 | Prior: 0.4144 | Triplet: 0.0787 | Eng: 0.2133\n",
      "Epoch 40/150 | Total: 0.4045 | MSE: 0.2503 | Prior: 0.4209 | Triplet: 0.0740 | Eng: 0.1950\n",
      "Epoch 50/150 | Total: 0.3907 | MSE: 0.2415 | Prior: 0.4262 | Triplet: 0.0672 | Eng: 0.1802\n",
      "Epoch 60/150 | Total: 0.3696 | MSE: 0.2289 | Prior: 0.4255 | Triplet: 0.0584 | Eng: 0.1566\n",
      "Epoch 70/150 | Total: 0.3509 | MSE: 0.2146 | Prior: 0.4291 | Triplet: 0.0527 | Eng: 0.1433\n",
      "Epoch 80/150 | Total: 0.3236 | MSE: 0.1966 | Prior: 0.4329 | Triplet: 0.0406 | Eng: 0.1201\n",
      "Epoch 90/150 | Total: 0.3283 | MSE: 0.2013 | Prior: 0.4318 | Triplet: 0.0416 | Eng: 0.1184\n",
      "Epoch 100/150 | Total: 0.3130 | MSE: 0.1927 | Prior: 0.4336 | Triplet: 0.0338 | Eng: 0.0999\n",
      "Epoch 110/150 | Total: 0.3010 | MSE: 0.1818 | Prior: 0.4379 | Triplet: 0.0302 | Eng: 0.1001\n",
      "Epoch 120/150 | Total: 0.2939 | MSE: 0.1711 | Prior: 0.4408 | Triplet: 0.0358 | Eng: 0.0999\n",
      "Epoch 130/150 | Total: 0.2891 | MSE: 0.1685 | Prior: 0.4427 | Triplet: 0.0341 | Eng: 0.0890\n",
      "Epoch 140/150 | Total: 0.2833 | MSE: 0.1664 | Prior: 0.4433 | Triplet: 0.0299 | Eng: 0.0782\n",
      "Epoch 150/150 | Total: 0.2781 | MSE: 0.1624 | Prior: 0.4438 | Triplet: 0.0278 | Eng: 0.0778\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2781\n",
      "  Min Loss: 0.2721\n",
      "  Wasserstein: 0.7515\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5516 | MSE: 0.3325 | Prior: 0.4284 | Triplet: 0.1470 | Eng: 0.3500\n",
      "Epoch 20/150 | Total: 0.4733 | MSE: 0.2915 | Prior: 0.4248 | Triplet: 0.1048 | Eng: 0.2612\n",
      "Epoch 30/150 | Total: 0.4243 | MSE: 0.2671 | Prior: 0.4235 | Triplet: 0.0778 | Eng: 0.1978\n",
      "Epoch 40/150 | Total: 0.3925 | MSE: 0.2436 | Prior: 0.4256 | Triplet: 0.0661 | Eng: 0.1828\n",
      "Epoch 50/150 | Total: 0.3691 | MSE: 0.2269 | Prior: 0.4295 | Triplet: 0.0530 | Eng: 0.1807\n",
      "Epoch 60/150 | Total: 0.3562 | MSE: 0.2197 | Prior: 0.4278 | Triplet: 0.0513 | Eng: 0.1520\n",
      "Epoch 70/150 | Total: 0.3390 | MSE: 0.2037 | Prior: 0.4349 | Triplet: 0.0461 | Eng: 0.1527\n",
      "Epoch 80/150 | Total: 0.3265 | MSE: 0.1971 | Prior: 0.4347 | Triplet: 0.0405 | Eng: 0.1343\n",
      "Epoch 90/150 | Total: 0.3119 | MSE: 0.1880 | Prior: 0.4387 | Triplet: 0.0345 | Eng: 0.1150\n",
      "Epoch 100/150 | Total: 0.3085 | MSE: 0.1831 | Prior: 0.4398 | Triplet: 0.0365 | Eng: 0.1153\n",
      "Epoch 110/150 | Total: 0.3016 | MSE: 0.1772 | Prior: 0.4418 | Triplet: 0.0355 | Eng: 0.1096\n",
      "Epoch 120/150 | Total: 0.2881 | MSE: 0.1662 | Prior: 0.4431 | Triplet: 0.0326 | Eng: 0.1028\n",
      "Epoch 130/150 | Total: 0.2856 | MSE: 0.1656 | Prior: 0.4434 | Triplet: 0.0320 | Eng: 0.0915\n",
      "Epoch 140/150 | Total: 0.2836 | MSE: 0.1634 | Prior: 0.4449 | Triplet: 0.0312 | Eng: 0.0942\n",
      "Epoch 150/150 | Total: 0.2772 | MSE: 0.1597 | Prior: 0.4428 | Triplet: 0.0306 | Eng: 0.0811\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2772\n",
      "  Min Loss: 0.2762\n",
      "  Wasserstein: 0.8559\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5203 | MSE: 0.3259 | Prior: 0.4241 | Triplet: 0.1277 | Eng: 0.2623\n",
      "Epoch 20/150 | Total: 0.4578 | MSE: 0.2917 | Prior: 0.4168 | Triplet: 0.0983 | Eng: 0.1912\n",
      "Epoch 30/150 | Total: 0.4074 | MSE: 0.2581 | Prior: 0.4252 | Triplet: 0.0729 | Eng: 0.1610\n",
      "Epoch 40/150 | Total: 0.3822 | MSE: 0.2434 | Prior: 0.4198 | Triplet: 0.0627 | Eng: 0.1351\n",
      "Epoch 50/150 | Total: 0.3758 | MSE: 0.2392 | Prior: 0.4268 | Triplet: 0.0583 | Eng: 0.1277\n",
      "Epoch 60/150 | Total: 0.3598 | MSE: 0.2255 | Prior: 0.4258 | Triplet: 0.0542 | Eng: 0.1289\n",
      "Epoch 70/150 | Total: 0.3432 | MSE: 0.2135 | Prior: 0.4318 | Triplet: 0.0464 | Eng: 0.1191\n",
      "Epoch 80/150 | Total: 0.3238 | MSE: 0.2005 | Prior: 0.4336 | Triplet: 0.0364 | Eng: 0.1103\n",
      "Epoch 90/150 | Total: 0.3104 | MSE: 0.1910 | Prior: 0.4369 | Triplet: 0.0342 | Eng: 0.0881\n",
      "Epoch 100/150 | Total: 0.3012 | MSE: 0.1823 | Prior: 0.4385 | Triplet: 0.0315 | Eng: 0.0927\n",
      "Epoch 110/150 | Total: 0.2958 | MSE: 0.1775 | Prior: 0.4382 | Triplet: 0.0294 | Eng: 0.0960\n",
      "Epoch 120/150 | Total: 0.2887 | MSE: 0.1680 | Prior: 0.4443 | Triplet: 0.0319 | Eng: 0.0955\n",
      "Epoch 130/150 | Total: 0.2788 | MSE: 0.1602 | Prior: 0.4449 | Triplet: 0.0300 | Eng: 0.0872\n",
      "Epoch 140/150 | Total: 0.2798 | MSE: 0.1646 | Prior: 0.4437 | Triplet: 0.0257 | Eng: 0.0824\n",
      "Epoch 150/150 | Total: 0.2722 | MSE: 0.1602 | Prior: 0.4435 | Triplet: 0.0212 | Eng: 0.0779\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2722\n",
      "  Min Loss: 0.2698\n",
      "  Wasserstein: 0.6648\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5304 | MSE: 0.3286 | Prior: 0.4249 | Triplet: 0.1397 | Eng: 0.2663\n",
      "Epoch 20/150 | Total: 0.4570 | MSE: 0.2843 | Prior: 0.4221 | Triplet: 0.1008 | Eng: 0.2184\n",
      "Epoch 30/150 | Total: 0.4111 | MSE: 0.2608 | Prior: 0.4252 | Triplet: 0.0743 | Eng: 0.1626\n",
      "Epoch 40/150 | Total: 0.3837 | MSE: 0.2464 | Prior: 0.4233 | Triplet: 0.0596 | Eng: 0.1322\n",
      "Epoch 50/150 | Total: 0.3627 | MSE: 0.2273 | Prior: 0.4273 | Triplet: 0.0552 | Eng: 0.1309\n",
      "Epoch 60/150 | Total: 0.3362 | MSE: 0.2085 | Prior: 0.4344 | Triplet: 0.0416 | Eng: 0.1199\n",
      "Epoch 70/150 | Total: 0.3234 | MSE: 0.2004 | Prior: 0.4322 | Triplet: 0.0381 | Eng: 0.1039\n",
      "Epoch 80/150 | Total: 0.3124 | MSE: 0.1919 | Prior: 0.4325 | Triplet: 0.0342 | Eng: 0.1016\n",
      "Epoch 90/150 | Total: 0.2960 | MSE: 0.1770 | Prior: 0.4394 | Triplet: 0.0310 | Eng: 0.0944\n",
      "Epoch 100/150 | Total: 0.2878 | MSE: 0.1691 | Prior: 0.4405 | Triplet: 0.0316 | Eng: 0.0883\n",
      "Epoch 110/150 | Total: 0.2875 | MSE: 0.1704 | Prior: 0.4437 | Triplet: 0.0271 | Eng: 0.0894\n",
      "Epoch 120/150 | Total: 0.2825 | MSE: 0.1682 | Prior: 0.4413 | Triplet: 0.0272 | Eng: 0.0740\n",
      "Epoch 130/150 | Total: 0.2815 | MSE: 0.1654 | Prior: 0.4418 | Triplet: 0.0287 | Eng: 0.0794\n",
      "Epoch 140/150 | Total: 0.2735 | MSE: 0.1602 | Prior: 0.4421 | Triplet: 0.0241 | Eng: 0.0778\n",
      "Epoch 150/150 | Total: 0.2678 | MSE: 0.1498 | Prior: 0.4452 | Triplet: 0.0287 | Eng: 0.0877\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2678\n",
      "  Min Loss: 0.2678\n",
      "  Wasserstein: 0.6813\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5824 | MSE: 0.3450 | Prior: 0.4181 | Triplet: 0.1484 | Eng: 0.4807\n",
      "Epoch 20/150 | Total: 0.4928 | MSE: 0.2954 | Prior: 0.4131 | Triplet: 0.1108 | Eng: 0.3595\n",
      "Epoch 30/150 | Total: 0.4437 | MSE: 0.2630 | Prior: 0.4203 | Triplet: 0.0881 | Eng: 0.3212\n",
      "Epoch 40/150 | Total: 0.4125 | MSE: 0.2487 | Prior: 0.4253 | Triplet: 0.0665 | Eng: 0.2814\n",
      "Epoch 50/150 | Total: 0.3933 | MSE: 0.2369 | Prior: 0.4278 | Triplet: 0.0608 | Eng: 0.2496\n",
      "Epoch 60/150 | Total: 0.3727 | MSE: 0.2246 | Prior: 0.4295 | Triplet: 0.0558 | Eng: 0.2099\n",
      "Epoch 70/150 | Total: 0.3667 | MSE: 0.2209 | Prior: 0.4348 | Triplet: 0.0465 | Eng: 0.2218\n",
      "Epoch 80/150 | Total: 0.3465 | MSE: 0.2067 | Prior: 0.4350 | Triplet: 0.0405 | Eng: 0.2037\n",
      "Epoch 90/150 | Total: 0.3387 | MSE: 0.1940 | Prior: 0.4403 | Triplet: 0.0477 | Eng: 0.2022\n",
      "Epoch 100/150 | Total: 0.3208 | MSE: 0.1855 | Prior: 0.4416 | Triplet: 0.0424 | Eng: 0.1582\n",
      "Epoch 110/150 | Total: 0.3141 | MSE: 0.1813 | Prior: 0.4430 | Triplet: 0.0334 | Eng: 0.1725\n",
      "Epoch 120/150 | Total: 0.3032 | MSE: 0.1709 | Prior: 0.4480 | Triplet: 0.0376 | Eng: 0.1471\n",
      "Epoch 130/150 | Total: 0.3048 | MSE: 0.1762 | Prior: 0.4426 | Triplet: 0.0328 | Eng: 0.1470\n",
      "Epoch 140/150 | Total: 0.2886 | MSE: 0.1635 | Prior: 0.4468 | Triplet: 0.0331 | Eng: 0.1173\n",
      "Epoch 150/150 | Total: 0.2860 | MSE: 0.1575 | Prior: 0.4483 | Triplet: 0.0326 | Eng: 0.1388\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2860\n",
      "  Min Loss: 0.2860\n",
      "  Wasserstein: 0.5151\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5501 | MSE: 0.3251 | Prior: 0.4117 | Triplet: 0.1477 | Eng: 0.4096\n",
      "Epoch 20/150 | Total: 0.4910 | MSE: 0.2924 | Prior: 0.4130 | Triplet: 0.1145 | Eng: 0.3529\n",
      "Epoch 30/150 | Total: 0.4376 | MSE: 0.2635 | Prior: 0.4237 | Triplet: 0.0838 | Eng: 0.2889\n",
      "Epoch 40/150 | Total: 0.4111 | MSE: 0.2514 | Prior: 0.4243 | Triplet: 0.0694 | Eng: 0.2449\n",
      "Epoch 50/150 | Total: 0.3912 | MSE: 0.2339 | Prior: 0.4292 | Triplet: 0.0582 | Eng: 0.2623\n",
      "Epoch 60/150 | Total: 0.3744 | MSE: 0.2235 | Prior: 0.4328 | Triplet: 0.0557 | Eng: 0.2246\n",
      "Epoch 70/150 | Total: 0.3665 | MSE: 0.2195 | Prior: 0.4332 | Triplet: 0.0510 | Eng: 0.2150\n",
      "Epoch 80/150 | Total: 0.3457 | MSE: 0.2024 | Prior: 0.4355 | Triplet: 0.0479 | Eng: 0.1990\n",
      "Epoch 90/150 | Total: 0.3317 | MSE: 0.1951 | Prior: 0.4396 | Triplet: 0.0375 | Eng: 0.1874\n",
      "Epoch 100/150 | Total: 0.3257 | MSE: 0.1896 | Prior: 0.4427 | Triplet: 0.0393 | Eng: 0.1727\n",
      "Epoch 110/150 | Total: 0.3139 | MSE: 0.1780 | Prior: 0.4446 | Triplet: 0.0438 | Eng: 0.1527\n",
      "Epoch 120/150 | Total: 0.3046 | MSE: 0.1744 | Prior: 0.4460 | Triplet: 0.0361 | Eng: 0.1409\n",
      "Epoch 130/150 | Total: 0.3053 | MSE: 0.1748 | Prior: 0.4466 | Triplet: 0.0346 | Eng: 0.1476\n",
      "Epoch 140/150 | Total: 0.2964 | MSE: 0.1657 | Prior: 0.4474 | Triplet: 0.0362 | Eng: 0.1418\n",
      "Epoch 150/150 | Total: 0.2875 | MSE: 0.1605 | Prior: 0.4475 | Triplet: 0.0324 | Eng: 0.1319\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2875\n",
      "  Min Loss: 0.2875\n",
      "  Wasserstein: 0.7427\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5495 | MSE: 0.3248 | Prior: 0.4117 | Triplet: 0.1562 | Eng: 0.3766\n",
      "Epoch 20/150 | Total: 0.4579 | MSE: 0.2777 | Prior: 0.4174 | Triplet: 0.1006 | Eng: 0.2759\n",
      "Epoch 30/150 | Total: 0.4124 | MSE: 0.2506 | Prior: 0.4233 | Triplet: 0.0732 | Eng: 0.2462\n",
      "Epoch 40/150 | Total: 0.4009 | MSE: 0.2478 | Prior: 0.4252 | Triplet: 0.0639 | Eng: 0.2197\n",
      "Epoch 50/150 | Total: 0.3681 | MSE: 0.2263 | Prior: 0.4275 | Triplet: 0.0517 | Eng: 0.1855\n",
      "Epoch 60/150 | Total: 0.3639 | MSE: 0.2239 | Prior: 0.4307 | Triplet: 0.0471 | Eng: 0.1861\n",
      "Epoch 70/150 | Total: 0.3553 | MSE: 0.2142 | Prior: 0.4322 | Triplet: 0.0477 | Eng: 0.1896\n",
      "Epoch 80/150 | Total: 0.3347 | MSE: 0.2005 | Prior: 0.4383 | Triplet: 0.0399 | Eng: 0.1644\n",
      "Epoch 90/150 | Total: 0.3243 | MSE: 0.1956 | Prior: 0.4373 | Triplet: 0.0350 | Eng: 0.1464\n",
      "Epoch 100/150 | Total: 0.3104 | MSE: 0.1798 | Prior: 0.4420 | Triplet: 0.0340 | Eng: 0.1567\n",
      "Epoch 110/150 | Total: 0.3048 | MSE: 0.1782 | Prior: 0.4430 | Triplet: 0.0323 | Eng: 0.1349\n",
      "Epoch 120/150 | Total: 0.3027 | MSE: 0.1722 | Prior: 0.4470 | Triplet: 0.0330 | Eng: 0.1530\n",
      "Epoch 130/150 | Total: 0.2952 | MSE: 0.1709 | Prior: 0.4440 | Triplet: 0.0271 | Eng: 0.1371\n",
      "Epoch 140/150 | Total: 0.2917 | MSE: 0.1651 | Prior: 0.4482 | Triplet: 0.0301 | Eng: 0.1361\n",
      "Epoch 150/150 | Total: 0.2862 | MSE: 0.1605 | Prior: 0.4479 | Triplet: 0.0292 | Eng: 0.1342\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2862\n",
      "  Min Loss: 0.2804\n",
      "  Wasserstein: 0.7718\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 256, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5373 | MSE: 0.3182 | Prior: 0.4142 | Triplet: 0.1589 | Eng: 0.3257\n",
      "Epoch 20/150 | Total: 0.4384 | MSE: 0.2687 | Prior: 0.4228 | Triplet: 0.0917 | Eng: 0.2312\n",
      "Epoch 30/150 | Total: 0.4096 | MSE: 0.2487 | Prior: 0.4220 | Triplet: 0.0781 | Eng: 0.2233\n",
      "Epoch 40/150 | Total: 0.3917 | MSE: 0.2435 | Prior: 0.4241 | Triplet: 0.0611 | Eng: 0.1980\n",
      "Epoch 50/150 | Total: 0.3685 | MSE: 0.2228 | Prior: 0.4305 | Triplet: 0.0503 | Eng: 0.2129\n",
      "Epoch 60/150 | Total: 0.3567 | MSE: 0.2152 | Prior: 0.4308 | Triplet: 0.0485 | Eng: 0.1909\n",
      "Epoch 70/150 | Total: 0.3490 | MSE: 0.2135 | Prior: 0.4315 | Triplet: 0.0422 | Eng: 0.1729\n",
      "Epoch 80/150 | Total: 0.3288 | MSE: 0.1959 | Prior: 0.4372 | Triplet: 0.0384 | Eng: 0.1625\n",
      "Epoch 90/150 | Total: 0.3192 | MSE: 0.1891 | Prior: 0.4400 | Triplet: 0.0321 | Eng: 0.1631\n",
      "Epoch 100/150 | Total: 0.3045 | MSE: 0.1780 | Prior: 0.4423 | Triplet: 0.0312 | Eng: 0.1389\n",
      "Epoch 110/150 | Total: 0.3095 | MSE: 0.1772 | Prior: 0.4425 | Triplet: 0.0399 | Eng: 0.1458\n",
      "Epoch 120/150 | Total: 0.2958 | MSE: 0.1671 | Prior: 0.4448 | Triplet: 0.0327 | Eng: 0.1455\n",
      "Epoch 130/150 | Total: 0.2816 | MSE: 0.1594 | Prior: 0.4471 | Triplet: 0.0257 | Eng: 0.1249\n",
      "Epoch 140/150 | Total: 0.2856 | MSE: 0.1621 | Prior: 0.4465 | Triplet: 0.0292 | Eng: 0.1208\n",
      "Epoch 150/150 | Total: 0.2793 | MSE: 0.1554 | Prior: 0.4500 | Triplet: 0.0282 | Eng: 0.1225\n",
      "\n",
      "Results for {'hidden_dim': 256, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2793\n",
      "  Min Loss: 0.2774\n",
      "  Wasserstein: 0.6443\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5526 | MSE: 0.3295 | Prior: 0.4274 | Triplet: 0.1532 | Eng: 0.3560\n",
      "Epoch 20/150 | Total: 0.4833 | MSE: 0.2923 | Prior: 0.4187 | Triplet: 0.1214 | Eng: 0.2698\n",
      "Epoch 30/150 | Total: 0.4352 | MSE: 0.2693 | Prior: 0.4178 | Triplet: 0.0889 | Eng: 0.2233\n",
      "Epoch 40/150 | Total: 0.4049 | MSE: 0.2517 | Prior: 0.4230 | Triplet: 0.0744 | Eng: 0.1847\n",
      "Epoch 50/150 | Total: 0.3785 | MSE: 0.2330 | Prior: 0.4260 | Triplet: 0.0651 | Eng: 0.1634\n",
      "Epoch 60/150 | Total: 0.3683 | MSE: 0.2292 | Prior: 0.4289 | Triplet: 0.0532 | Eng: 0.1599\n",
      "Epoch 70/150 | Total: 0.3513 | MSE: 0.2136 | Prior: 0.4318 | Triplet: 0.0494 | Eng: 0.1611\n",
      "Epoch 80/150 | Total: 0.3304 | MSE: 0.2013 | Prior: 0.4360 | Triplet: 0.0386 | Eng: 0.1375\n",
      "Epoch 90/150 | Total: 0.3232 | MSE: 0.1952 | Prior: 0.4360 | Triplet: 0.0390 | Eng: 0.1292\n",
      "Epoch 100/150 | Total: 0.3096 | MSE: 0.1788 | Prior: 0.4415 | Triplet: 0.0425 | Eng: 0.1275\n",
      "Epoch 110/150 | Total: 0.2977 | MSE: 0.1713 | Prior: 0.4428 | Triplet: 0.0377 | Eng: 0.1141\n",
      "Epoch 120/150 | Total: 0.2888 | MSE: 0.1668 | Prior: 0.4452 | Triplet: 0.0325 | Eng: 0.1009\n",
      "Epoch 130/150 | Total: 0.2810 | MSE: 0.1643 | Prior: 0.4424 | Triplet: 0.0289 | Eng: 0.0818\n",
      "Epoch 140/150 | Total: 0.2856 | MSE: 0.1662 | Prior: 0.4463 | Triplet: 0.0305 | Eng: 0.0893\n",
      "Epoch 150/150 | Total: 0.2806 | MSE: 0.1612 | Prior: 0.4467 | Triplet: 0.0292 | Eng: 0.0933\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2806\n",
      "  Min Loss: 0.2710\n",
      "  Wasserstein: 0.7018\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5531 | MSE: 0.3247 | Prior: 0.4281 | Triplet: 0.1482 | Eng: 0.4088\n",
      "Epoch 20/150 | Total: 0.4565 | MSE: 0.2796 | Prior: 0.4253 | Triplet: 0.0992 | Eng: 0.2486\n",
      "Epoch 30/150 | Total: 0.4238 | MSE: 0.2602 | Prior: 0.4225 | Triplet: 0.0817 | Eng: 0.2279\n",
      "Epoch 40/150 | Total: 0.3953 | MSE: 0.2436 | Prior: 0.4235 | Triplet: 0.0696 | Eng: 0.1918\n",
      "Epoch 50/150 | Total: 0.3720 | MSE: 0.2321 | Prior: 0.4247 | Triplet: 0.0549 | Eng: 0.1648\n",
      "Epoch 60/150 | Total: 0.3551 | MSE: 0.2158 | Prior: 0.4274 | Triplet: 0.0534 | Eng: 0.1628\n",
      "Epoch 70/150 | Total: 0.3489 | MSE: 0.2177 | Prior: 0.4265 | Triplet: 0.0476 | Eng: 0.1313\n",
      "Epoch 80/150 | Total: 0.3260 | MSE: 0.1961 | Prior: 0.4340 | Triplet: 0.0426 | Eng: 0.1315\n",
      "Epoch 90/150 | Total: 0.3164 | MSE: 0.1917 | Prior: 0.4372 | Triplet: 0.0395 | Eng: 0.1033\n",
      "Epoch 100/150 | Total: 0.3056 | MSE: 0.1816 | Prior: 0.4389 | Triplet: 0.0361 | Eng: 0.1091\n",
      "Epoch 110/150 | Total: 0.2974 | MSE: 0.1770 | Prior: 0.4382 | Triplet: 0.0334 | Eng: 0.0966\n",
      "Epoch 120/150 | Total: 0.2904 | MSE: 0.1692 | Prior: 0.4425 | Triplet: 0.0317 | Eng: 0.1018\n",
      "Epoch 130/150 | Total: 0.2815 | MSE: 0.1631 | Prior: 0.4421 | Triplet: 0.0285 | Eng: 0.0952\n",
      "Epoch 140/150 | Total: 0.2854 | MSE: 0.1645 | Prior: 0.4467 | Triplet: 0.0311 | Eng: 0.0967\n",
      "Epoch 150/150 | Total: 0.2725 | MSE: 0.1555 | Prior: 0.4460 | Triplet: 0.0291 | Eng: 0.0789\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 2, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2725\n",
      "  Min Loss: 0.2725\n",
      "  Wasserstein: 0.7134\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5352 | MSE: 0.3279 | Prior: 0.4199 | Triplet: 0.1497 | Eng: 0.2739\n",
      "Epoch 20/150 | Total: 0.4551 | MSE: 0.2875 | Prior: 0.4218 | Triplet: 0.0912 | Eng: 0.2204\n",
      "Epoch 30/150 | Total: 0.4177 | MSE: 0.2665 | Prior: 0.4218 | Triplet: 0.0718 | Eng: 0.1820\n",
      "Epoch 40/150 | Total: 0.3827 | MSE: 0.2414 | Prior: 0.4225 | Triplet: 0.0637 | Eng: 0.1455\n",
      "Epoch 50/150 | Total: 0.3558 | MSE: 0.2228 | Prior: 0.4282 | Triplet: 0.0497 | Eng: 0.1341\n",
      "Epoch 60/150 | Total: 0.3420 | MSE: 0.2137 | Prior: 0.4295 | Triplet: 0.0451 | Eng: 0.1173\n",
      "Epoch 70/150 | Total: 0.3282 | MSE: 0.2009 | Prior: 0.4323 | Triplet: 0.0414 | Eng: 0.1199\n",
      "Epoch 80/150 | Total: 0.3288 | MSE: 0.2026 | Prior: 0.4321 | Triplet: 0.0421 | Eng: 0.1109\n",
      "Epoch 90/150 | Total: 0.3041 | MSE: 0.1800 | Prior: 0.4395 | Triplet: 0.0332 | Eng: 0.1203\n",
      "Epoch 100/150 | Total: 0.2934 | MSE: 0.1745 | Prior: 0.4394 | Triplet: 0.0293 | Eng: 0.0996\n",
      "Epoch 110/150 | Total: 0.2894 | MSE: 0.1697 | Prior: 0.4426 | Triplet: 0.0307 | Eng: 0.0956\n",
      "Epoch 120/150 | Total: 0.2819 | MSE: 0.1622 | Prior: 0.4426 | Triplet: 0.0276 | Eng: 0.1065\n",
      "Epoch 130/150 | Total: 0.2738 | MSE: 0.1560 | Prior: 0.4437 | Triplet: 0.0292 | Eng: 0.0863\n",
      "Epoch 140/150 | Total: 0.2756 | MSE: 0.1563 | Prior: 0.4443 | Triplet: 0.0269 | Eng: 0.1042\n",
      "Epoch 150/150 | Total: 0.2659 | MSE: 0.1514 | Prior: 0.4479 | Triplet: 0.0235 | Eng: 0.0798\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2659\n",
      "  Min Loss: 0.2626\n",
      "  Wasserstein: 0.5947\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5340 | MSE: 0.3264 | Prior: 0.4212 | Triplet: 0.1418 | Eng: 0.3025\n",
      "Epoch 20/150 | Total: 0.4495 | MSE: 0.2843 | Prior: 0.4235 | Triplet: 0.0912 | Eng: 0.2026\n",
      "Epoch 30/150 | Total: 0.4093 | MSE: 0.2592 | Prior: 0.4231 | Triplet: 0.0740 | Eng: 0.1657\n",
      "Epoch 40/150 | Total: 0.3759 | MSE: 0.2349 | Prior: 0.4256 | Triplet: 0.0581 | Eng: 0.1589\n",
      "Epoch 50/150 | Total: 0.3506 | MSE: 0.2186 | Prior: 0.4287 | Triplet: 0.0500 | Eng: 0.1250\n",
      "Epoch 60/150 | Total: 0.3419 | MSE: 0.2142 | Prior: 0.4270 | Triplet: 0.0437 | Eng: 0.1216\n",
      "Epoch 70/150 | Total: 0.3275 | MSE: 0.2026 | Prior: 0.4319 | Triplet: 0.0401 | Eng: 0.1095\n",
      "Epoch 80/150 | Total: 0.3248 | MSE: 0.2022 | Prior: 0.4325 | Triplet: 0.0348 | Eng: 0.1130\n",
      "Epoch 90/150 | Total: 0.3099 | MSE: 0.1896 | Prior: 0.4373 | Triplet: 0.0310 | Eng: 0.1056\n",
      "Epoch 100/150 | Total: 0.3012 | MSE: 0.1803 | Prior: 0.4382 | Triplet: 0.0299 | Eng: 0.1122\n",
      "Epoch 110/150 | Total: 0.2894 | MSE: 0.1729 | Prior: 0.4389 | Triplet: 0.0273 | Eng: 0.0914\n",
      "Epoch 120/150 | Total: 0.2921 | MSE: 0.1719 | Prior: 0.4416 | Triplet: 0.0291 | Eng: 0.1062\n",
      "Epoch 130/150 | Total: 0.2849 | MSE: 0.1690 | Prior: 0.4412 | Triplet: 0.0251 | Eng: 0.0925\n",
      "Epoch 140/150 | Total: 0.2804 | MSE: 0.1628 | Prior: 0.4430 | Triplet: 0.0265 | Eng: 0.0961\n",
      "Epoch 150/150 | Total: 0.2708 | MSE: 0.1547 | Prior: 0.4445 | Triplet: 0.0252 | Eng: 0.0888\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 2, 'activation': 'GELU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2708\n",
      "  Min Loss: 0.2685\n",
      "  Wasserstein: 0.8335\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5668 | MSE: 0.3299 | Prior: 0.4164 | Triplet: 0.1588 | Eng: 0.4412\n",
      "Epoch 20/150 | Total: 0.4823 | MSE: 0.2917 | Prior: 0.4134 | Triplet: 0.1086 | Eng: 0.3216\n",
      "Epoch 30/150 | Total: 0.4394 | MSE: 0.2631 | Prior: 0.4206 | Triplet: 0.0872 | Eng: 0.2946\n",
      "Epoch 40/150 | Total: 0.4159 | MSE: 0.2477 | Prior: 0.4205 | Triplet: 0.0747 | Eng: 0.2863\n",
      "Epoch 50/150 | Total: 0.4020 | MSE: 0.2414 | Prior: 0.4287 | Triplet: 0.0683 | Eng: 0.2481\n",
      "Epoch 60/150 | Total: 0.3803 | MSE: 0.2277 | Prior: 0.4311 | Triplet: 0.0586 | Eng: 0.2279\n",
      "Epoch 70/150 | Total: 0.3573 | MSE: 0.2140 | Prior: 0.4357 | Triplet: 0.0539 | Eng: 0.1769\n",
      "Epoch 80/150 | Total: 0.3402 | MSE: 0.2020 | Prior: 0.4371 | Triplet: 0.0419 | Eng: 0.1844\n",
      "Epoch 90/150 | Total: 0.3366 | MSE: 0.1998 | Prior: 0.4380 | Triplet: 0.0445 | Eng: 0.1648\n",
      "Epoch 100/150 | Total: 0.3209 | MSE: 0.1827 | Prior: 0.4410 | Triplet: 0.0439 | Eng: 0.1730\n",
      "Epoch 110/150 | Total: 0.3127 | MSE: 0.1805 | Prior: 0.4415 | Triplet: 0.0379 | Eng: 0.1533\n",
      "Epoch 120/150 | Total: 0.3100 | MSE: 0.1788 | Prior: 0.4391 | Triplet: 0.0352 | Eng: 0.1601\n",
      "Epoch 130/150 | Total: 0.3024 | MSE: 0.1729 | Prior: 0.4430 | Triplet: 0.0359 | Eng: 0.1412\n",
      "Epoch 140/150 | Total: 0.2998 | MSE: 0.1709 | Prior: 0.4431 | Triplet: 0.0379 | Eng: 0.1294\n",
      "Epoch 150/150 | Total: 0.2944 | MSE: 0.1662 | Prior: 0.4471 | Triplet: 0.0346 | Eng: 0.1320\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2944\n",
      "  Min Loss: 0.2899\n",
      "  Wasserstein: 0.7228\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'} ===\n",
      "Epoch 10/150 | Total: 0.5790 | MSE: 0.3311 | Prior: 0.4085 | Triplet: 0.1854 | Eng: 0.4282\n",
      "Epoch 20/150 | Total: 0.4999 | MSE: 0.2957 | Prior: 0.4135 | Triplet: 0.1277 | Eng: 0.3419\n",
      "Epoch 30/150 | Total: 0.4583 | MSE: 0.2716 | Prior: 0.4226 | Triplet: 0.0966 | Eng: 0.3270\n",
      "Epoch 40/150 | Total: 0.4322 | MSE: 0.2624 | Prior: 0.4218 | Triplet: 0.0793 | Eng: 0.2790\n",
      "Epoch 50/150 | Total: 0.4030 | MSE: 0.2466 | Prior: 0.4251 | Triplet: 0.0665 | Eng: 0.2325\n",
      "Epoch 60/150 | Total: 0.3877 | MSE: 0.2329 | Prior: 0.4302 | Triplet: 0.0602 | Eng: 0.2376\n",
      "Epoch 70/150 | Total: 0.3725 | MSE: 0.2254 | Prior: 0.4300 | Triplet: 0.0494 | Eng: 0.2266\n",
      "Epoch 80/150 | Total: 0.3535 | MSE: 0.2124 | Prior: 0.4333 | Triplet: 0.0464 | Eng: 0.1932\n",
      "Epoch 90/150 | Total: 0.3462 | MSE: 0.2081 | Prior: 0.4344 | Triplet: 0.0422 | Eng: 0.1863\n",
      "Epoch 100/150 | Total: 0.3313 | MSE: 0.1950 | Prior: 0.4401 | Triplet: 0.0400 | Eng: 0.1754\n",
      "Epoch 110/150 | Total: 0.3122 | MSE: 0.1828 | Prior: 0.4416 | Triplet: 0.0305 | Eng: 0.1619\n",
      "Epoch 120/150 | Total: 0.3146 | MSE: 0.1807 | Prior: 0.4431 | Triplet: 0.0387 | Eng: 0.1606\n",
      "Epoch 130/150 | Total: 0.3067 | MSE: 0.1759 | Prior: 0.4431 | Triplet: 0.0358 | Eng: 0.1495\n",
      "Epoch 140/150 | Total: 0.3017 | MSE: 0.1734 | Prior: 0.4463 | Triplet: 0.0331 | Eng: 0.1387\n",
      "Epoch 150/150 | Total: 0.2923 | MSE: 0.1661 | Prior: 0.4445 | Triplet: 0.0314 | Eng: 0.1336\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 3, 'activation': 'LeakyReLU', 'optimizer_type': 'AdamW'}:\n",
      "  Final Loss: 0.2923\n",
      "  Min Loss: 0.2825\n",
      "  Wasserstein: 0.7381\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'} ===\n",
      "Epoch 10/150 | Total: 0.5153 | MSE: 0.3082 | Prior: 0.4128 | Triplet: 0.1227 | Eng: 0.3807\n",
      "Epoch 20/150 | Total: 0.4452 | MSE: 0.2746 | Prior: 0.4187 | Triplet: 0.0859 | Eng: 0.2641\n",
      "Epoch 30/150 | Total: 0.4046 | MSE: 0.2430 | Prior: 0.4254 | Triplet: 0.0708 | Eng: 0.2499\n",
      "Epoch 40/150 | Total: 0.3881 | MSE: 0.2334 | Prior: 0.4295 | Triplet: 0.0640 | Eng: 0.2238\n",
      "Epoch 50/150 | Total: 0.3765 | MSE: 0.2240 | Prior: 0.4347 | Triplet: 0.0590 | Eng: 0.2203\n",
      "Epoch 60/150 | Total: 0.3581 | MSE: 0.2150 | Prior: 0.4370 | Triplet: 0.0477 | Eng: 0.1967\n",
      "Epoch 70/150 | Total: 0.3424 | MSE: 0.2091 | Prior: 0.4333 | Triplet: 0.0431 | Eng: 0.1529\n",
      "Epoch 80/150 | Total: 0.3367 | MSE: 0.1966 | Prior: 0.4384 | Triplet: 0.0389 | Eng: 0.2072\n",
      "Epoch 90/150 | Total: 0.3305 | MSE: 0.1921 | Prior: 0.4424 | Triplet: 0.0426 | Eng: 0.1767\n",
      "Epoch 100/150 | Total: 0.3146 | MSE: 0.1829 | Prior: 0.4425 | Triplet: 0.0339 | Eng: 0.1633\n",
      "Epoch 110/150 | Total: 0.3033 | MSE: 0.1710 | Prior: 0.4429 | Triplet: 0.0348 | Eng: 0.1638\n",
      "Epoch 120/150 | Total: 0.3062 | MSE: 0.1774 | Prior: 0.4436 | Triplet: 0.0315 | Eng: 0.1516\n",
      "Epoch 130/150 | Total: 0.2912 | MSE: 0.1605 | Prior: 0.4475 | Triplet: 0.0332 | Eng: 0.1529\n",
      "Epoch 140/150 | Total: 0.2852 | MSE: 0.1577 | Prior: 0.4461 | Triplet: 0.0319 | Eng: 0.1383\n",
      "Epoch 150/150 | Total: 0.2849 | MSE: 0.1596 | Prior: 0.4482 | Triplet: 0.0290 | Eng: 0.1316\n",
      "\n",
      "Results for {'hidden_dim': 288, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'Adam'}:\n",
      "  Final Loss: 0.2849\n",
      "  Min Loss: 0.2822\n",
      "  Wasserstein: 0.7612\n",
      "----------------------------\n",
      "\n",
      "=== Testing {'hidden_dim': 288, 'num_layers': 3, 'activation': 'GELU', 'optimizer_type': 'AdamW'} ===\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "# Step 6: Run Architectural Search\n",
    "#############################################\n",
    "arch_search_space = {\n",
    "    'hidden_dim': [224, 256, 288],\n",
    "    'num_layers': [2, 3],\n",
    "    'activation': ['LeakyReLU', 'GELU'],\n",
    "    'optimizer_type': ['Adam', 'AdamW']\n",
    "}\n",
    "\n",
    "results = []\n",
    "for config in [dict(zip(arch_search_space.keys(), vals)) \n",
    "              for vals in product(*arch_search_space.values())]:\n",
    "    \n",
    "    print(f\"\\n=== Testing {config} ===\")\n",
    "    model, loss_components = train_arch_config(config)\n",
    "    ws_dist = evaluate_model(model)\n",
    "    \n",
    "    results.append({\n",
    "        **config,\n",
    "        'wasserstein': ws_dist,\n",
    "        'loss_components': loss_components,\n",
    "        'final_loss': loss_components['total'][-1],\n",
    "        'min_loss': min(loss_components['total'])\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nResults for {config}:\")\n",
    "    print(f\"  Final Loss: {loss_components['total'][-1]:.4f}\")\n",
    "    print(f\"  Min Loss: {min(loss_components['total']):.4f}\")\n",
    "    print(f\"  Wasserstein: {ws_dist:.4f}\")\n",
    "    print(\"----------------------------\")\n",
    "\n",
    "plot_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Env1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
